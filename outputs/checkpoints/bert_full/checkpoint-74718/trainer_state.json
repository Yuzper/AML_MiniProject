{
  "best_global_step": 74718,
  "best_metric": 0.9840065312240691,
  "best_model_checkpoint": "outputs/checkpoints/bert_full/checkpoint-74718",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 74718,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006691827939720014,
      "grad_norm": 0.04796206206083298,
      "learning_rate": 1.9973286222864637e-05,
      "loss": 0.1402,
      "step": 500
    },
    {
      "epoch": 0.013383655879440027,
      "grad_norm": 0.3119257390499115,
      "learning_rate": 1.9946625980352794e-05,
      "loss": 0.106,
      "step": 1000
    },
    {
      "epoch": 0.020075483819160043,
      "grad_norm": 0.024958932772278786,
      "learning_rate": 1.9919858668593914e-05,
      "loss": 0.1011,
      "step": 1500
    },
    {
      "epoch": 0.026767311758880055,
      "grad_norm": 0.013468916527926922,
      "learning_rate": 1.9893091356835034e-05,
      "loss": 0.0745,
      "step": 2000
    },
    {
      "epoch": 0.03345913969860007,
      "grad_norm": 9.817083358764648,
      "learning_rate": 1.9866377579699673e-05,
      "loss": 0.0799,
      "step": 2500
    },
    {
      "epoch": 0.04015096763832009,
      "grad_norm": 0.03618215397000313,
      "learning_rate": 1.9839663802564312e-05,
      "loss": 0.0617,
      "step": 3000
    },
    {
      "epoch": 0.046842795578040095,
      "grad_norm": 0.005474668461829424,
      "learning_rate": 1.9812896490805432e-05,
      "loss": 0.062,
      "step": 3500
    },
    {
      "epoch": 0.05353462351776011,
      "grad_norm": 0.14690949022769928,
      "learning_rate": 1.978612917904655e-05,
      "loss": 0.0646,
      "step": 4000
    },
    {
      "epoch": 0.060226451457480124,
      "grad_norm": 5.731198310852051,
      "learning_rate": 1.975936186728767e-05,
      "loss": 0.0507,
      "step": 4500
    },
    {
      "epoch": 0.06691827939720014,
      "grad_norm": 0.32261762022972107,
      "learning_rate": 1.973259455552879e-05,
      "loss": 0.0625,
      "step": 5000
    },
    {
      "epoch": 0.07361010733692015,
      "grad_norm": 0.041659314185380936,
      "learning_rate": 1.970582724376991e-05,
      "loss": 0.0549,
      "step": 5500
    },
    {
      "epoch": 0.08030193527664017,
      "grad_norm": 0.0012330882018432021,
      "learning_rate": 1.967905993201103e-05,
      "loss": 0.061,
      "step": 6000
    },
    {
      "epoch": 0.08699376321636018,
      "grad_norm": 0.0013861780753359199,
      "learning_rate": 1.965229262025215e-05,
      "loss": 0.064,
      "step": 6500
    },
    {
      "epoch": 0.09368559115608019,
      "grad_norm": 0.06197873130440712,
      "learning_rate": 1.962557884311679e-05,
      "loss": 0.0539,
      "step": 7000
    },
    {
      "epoch": 0.10037741909580021,
      "grad_norm": 5.5167646408081055,
      "learning_rate": 1.9598811531357906e-05,
      "loss": 0.0516,
      "step": 7500
    },
    {
      "epoch": 0.10706924703552022,
      "grad_norm": 34.947322845458984,
      "learning_rate": 1.9572044219599026e-05,
      "loss": 0.0509,
      "step": 8000
    },
    {
      "epoch": 0.11376107497524024,
      "grad_norm": 0.034620121121406555,
      "learning_rate": 1.9545276907840147e-05,
      "loss": 0.0614,
      "step": 8500
    },
    {
      "epoch": 0.12045290291496025,
      "grad_norm": 0.07794958353042603,
      "learning_rate": 1.9518563130704785e-05,
      "loss": 0.0588,
      "step": 9000
    },
    {
      "epoch": 0.12714473085468025,
      "grad_norm": 0.012425108812749386,
      "learning_rate": 1.9491795818945906e-05,
      "loss": 0.0533,
      "step": 9500
    },
    {
      "epoch": 0.1338365587944003,
      "grad_norm": 0.002988613909110427,
      "learning_rate": 1.9465028507187026e-05,
      "loss": 0.0591,
      "step": 10000
    },
    {
      "epoch": 0.1405283867341203,
      "grad_norm": 0.008023136295378208,
      "learning_rate": 1.9438261195428146e-05,
      "loss": 0.0511,
      "step": 10500
    },
    {
      "epoch": 0.1472202146738403,
      "grad_norm": 0.0007601860561408103,
      "learning_rate": 1.9411493883669266e-05,
      "loss": 0.0384,
      "step": 11000
    },
    {
      "epoch": 0.1539120426135603,
      "grad_norm": 0.04046809300780296,
      "learning_rate": 1.9384780106533902e-05,
      "loss": 0.0456,
      "step": 11500
    },
    {
      "epoch": 0.16060387055328035,
      "grad_norm": 0.1691139191389084,
      "learning_rate": 1.9358012794775022e-05,
      "loss": 0.0511,
      "step": 12000
    },
    {
      "epoch": 0.16729569849300036,
      "grad_norm": 0.09799393266439438,
      "learning_rate": 1.9331245483016142e-05,
      "loss": 0.0525,
      "step": 12500
    },
    {
      "epoch": 0.17398752643272036,
      "grad_norm": 0.10024482756853104,
      "learning_rate": 1.9304478171257263e-05,
      "loss": 0.0584,
      "step": 13000
    },
    {
      "epoch": 0.18067935437244037,
      "grad_norm": 0.004843780770897865,
      "learning_rate": 1.9277710859498383e-05,
      "loss": 0.0531,
      "step": 13500
    },
    {
      "epoch": 0.18737118231216038,
      "grad_norm": 0.0018327045254409313,
      "learning_rate": 1.9250943547739503e-05,
      "loss": 0.0462,
      "step": 14000
    },
    {
      "epoch": 0.1940630102518804,
      "grad_norm": 0.39669570326805115,
      "learning_rate": 1.9224176235980624e-05,
      "loss": 0.0449,
      "step": 14500
    },
    {
      "epoch": 0.20075483819160042,
      "grad_norm": 0.005839720834046602,
      "learning_rate": 1.919746245884526e-05,
      "loss": 0.0407,
      "step": 15000
    },
    {
      "epoch": 0.20744666613132043,
      "grad_norm": 0.008322926238179207,
      "learning_rate": 1.917069514708638e-05,
      "loss": 0.0481,
      "step": 15500
    },
    {
      "epoch": 0.21413849407104044,
      "grad_norm": 58.176979064941406,
      "learning_rate": 1.91439278353275e-05,
      "loss": 0.0372,
      "step": 16000
    },
    {
      "epoch": 0.22083032201076047,
      "grad_norm": 0.03908105567097664,
      "learning_rate": 1.9117214058192138e-05,
      "loss": 0.0481,
      "step": 16500
    },
    {
      "epoch": 0.22752214995048048,
      "grad_norm": 0.055949293076992035,
      "learning_rate": 1.909044674643326e-05,
      "loss": 0.0484,
      "step": 17000
    },
    {
      "epoch": 0.2342139778902005,
      "grad_norm": 0.37154585123062134,
      "learning_rate": 1.906367943467438e-05,
      "loss": 0.0481,
      "step": 17500
    },
    {
      "epoch": 0.2409058058299205,
      "grad_norm": 6.115246772766113,
      "learning_rate": 1.9036965657539014e-05,
      "loss": 0.0607,
      "step": 18000
    },
    {
      "epoch": 0.2475976337696405,
      "grad_norm": 0.0021434242371469736,
      "learning_rate": 1.9010198345780134e-05,
      "loss": 0.0491,
      "step": 18500
    },
    {
      "epoch": 0.2542894617093605,
      "grad_norm": 0.0011307507520541549,
      "learning_rate": 1.8983431034021255e-05,
      "loss": 0.0406,
      "step": 19000
    },
    {
      "epoch": 0.2609812896490805,
      "grad_norm": 0.029870424419641495,
      "learning_rate": 1.8956663722262375e-05,
      "loss": 0.041,
      "step": 19500
    },
    {
      "epoch": 0.2676731175888006,
      "grad_norm": 0.15462139248847961,
      "learning_rate": 1.8929896410503495e-05,
      "loss": 0.0446,
      "step": 20000
    },
    {
      "epoch": 0.2743649455285206,
      "grad_norm": 21.894237518310547,
      "learning_rate": 1.8903182633368134e-05,
      "loss": 0.0418,
      "step": 20500
    },
    {
      "epoch": 0.2810567734682406,
      "grad_norm": 0.0015144560020416975,
      "learning_rate": 1.887641532160925e-05,
      "loss": 0.0508,
      "step": 21000
    },
    {
      "epoch": 0.2877486014079606,
      "grad_norm": 0.05776594951748848,
      "learning_rate": 1.884964800985037e-05,
      "loss": 0.0427,
      "step": 21500
    },
    {
      "epoch": 0.2944404293476806,
      "grad_norm": 0.04988189786672592,
      "learning_rate": 1.882288069809149e-05,
      "loss": 0.0347,
      "step": 22000
    },
    {
      "epoch": 0.3011322572874006,
      "grad_norm": 0.030231794342398643,
      "learning_rate": 1.879611338633261e-05,
      "loss": 0.0503,
      "step": 22500
    },
    {
      "epoch": 0.3078240852271206,
      "grad_norm": 0.10336820036172867,
      "learning_rate": 1.8769346074573732e-05,
      "loss": 0.0478,
      "step": 23000
    },
    {
      "epoch": 0.31451591316684063,
      "grad_norm": 0.00644893292337656,
      "learning_rate": 1.8742578762814852e-05,
      "loss": 0.0366,
      "step": 23500
    },
    {
      "epoch": 0.3212077411065607,
      "grad_norm": 0.05720679089426994,
      "learning_rate": 1.8715811451055973e-05,
      "loss": 0.0446,
      "step": 24000
    },
    {
      "epoch": 0.3278995690462807,
      "grad_norm": 0.016544243320822716,
      "learning_rate": 1.8689097673920608e-05,
      "loss": 0.0364,
      "step": 24500
    },
    {
      "epoch": 0.3345913969860007,
      "grad_norm": 0.11171264946460724,
      "learning_rate": 1.8662330362161728e-05,
      "loss": 0.0426,
      "step": 25000
    },
    {
      "epoch": 0.3412832249257207,
      "grad_norm": 0.00344551051966846,
      "learning_rate": 1.863556305040285e-05,
      "loss": 0.0387,
      "step": 25500
    },
    {
      "epoch": 0.3479750528654407,
      "grad_norm": 0.01038755290210247,
      "learning_rate": 1.860879573864397e-05,
      "loss": 0.0307,
      "step": 26000
    },
    {
      "epoch": 0.35466688080516073,
      "grad_norm": 0.01718481257557869,
      "learning_rate": 1.858202842688509e-05,
      "loss": 0.04,
      "step": 26500
    },
    {
      "epoch": 0.36135870874488074,
      "grad_norm": 0.011422321200370789,
      "learning_rate": 1.855526111512621e-05,
      "loss": 0.0401,
      "step": 27000
    },
    {
      "epoch": 0.36805053668460075,
      "grad_norm": 0.10280390083789825,
      "learning_rate": 1.852849380336733e-05,
      "loss": 0.0378,
      "step": 27500
    },
    {
      "epoch": 0.37474236462432076,
      "grad_norm": 0.00888754427433014,
      "learning_rate": 1.850172649160845e-05,
      "loss": 0.0297,
      "step": 28000
    },
    {
      "epoch": 0.3814341925640408,
      "grad_norm": 0.002325992565602064,
      "learning_rate": 1.8475012714473085e-05,
      "loss": 0.0437,
      "step": 28500
    },
    {
      "epoch": 0.3881260205037608,
      "grad_norm": 0.001831004861742258,
      "learning_rate": 1.8448245402714205e-05,
      "loss": 0.0411,
      "step": 29000
    },
    {
      "epoch": 0.39481784844348083,
      "grad_norm": 0.0030924235470592976,
      "learning_rate": 1.8421478090955326e-05,
      "loss": 0.0463,
      "step": 29500
    },
    {
      "epoch": 0.40150967638320084,
      "grad_norm": 0.0014463290572166443,
      "learning_rate": 1.8394710779196446e-05,
      "loss": 0.032,
      "step": 30000
    },
    {
      "epoch": 0.40820150432292085,
      "grad_norm": 0.01593749038875103,
      "learning_rate": 1.8367943467437566e-05,
      "loss": 0.0436,
      "step": 30500
    },
    {
      "epoch": 0.41489333226264086,
      "grad_norm": 0.0017704571364447474,
      "learning_rate": 1.8341229690302205e-05,
      "loss": 0.0243,
      "step": 31000
    },
    {
      "epoch": 0.42158516020236086,
      "grad_norm": 0.019163450226187706,
      "learning_rate": 1.8314462378543325e-05,
      "loss": 0.0399,
      "step": 31500
    },
    {
      "epoch": 0.42827698814208087,
      "grad_norm": 0.01753789372742176,
      "learning_rate": 1.8287695066784442e-05,
      "loss": 0.0475,
      "step": 32000
    },
    {
      "epoch": 0.4349688160818009,
      "grad_norm": 0.023159803822636604,
      "learning_rate": 1.8260927755025563e-05,
      "loss": 0.0446,
      "step": 32500
    },
    {
      "epoch": 0.44166064402152094,
      "grad_norm": 0.003751636715605855,
      "learning_rate": 1.8234160443266683e-05,
      "loss": 0.047,
      "step": 33000
    },
    {
      "epoch": 0.44835247196124095,
      "grad_norm": 0.04879254102706909,
      "learning_rate": 1.8207393131507803e-05,
      "loss": 0.0359,
      "step": 33500
    },
    {
      "epoch": 0.45504429990096096,
      "grad_norm": 0.03544230759143829,
      "learning_rate": 1.8180625819748923e-05,
      "loss": 0.0415,
      "step": 34000
    },
    {
      "epoch": 0.46173612784068097,
      "grad_norm": 0.008522383868694305,
      "learning_rate": 1.8153858507990044e-05,
      "loss": 0.0354,
      "step": 34500
    },
    {
      "epoch": 0.468427955780401,
      "grad_norm": 0.1573578417301178,
      "learning_rate": 1.8127091196231164e-05,
      "loss": 0.0388,
      "step": 35000
    },
    {
      "epoch": 0.475119783720121,
      "grad_norm": 0.0008812965243123472,
      "learning_rate": 1.8100323884472284e-05,
      "loss": 0.0321,
      "step": 35500
    },
    {
      "epoch": 0.481811611659841,
      "grad_norm": 0.042298343032598495,
      "learning_rate": 1.8073556572713405e-05,
      "loss": 0.03,
      "step": 36000
    },
    {
      "epoch": 0.488503439599561,
      "grad_norm": 0.004292197059839964,
      "learning_rate": 1.8046789260954525e-05,
      "loss": 0.021,
      "step": 36500
    },
    {
      "epoch": 0.495195267539281,
      "grad_norm": 0.012195637449622154,
      "learning_rate": 1.8020021949195642e-05,
      "loss": 0.0379,
      "step": 37000
    },
    {
      "epoch": 0.501887095479001,
      "grad_norm": 0.003010038286447525,
      "learning_rate": 1.7993254637436762e-05,
      "loss": 0.0356,
      "step": 37500
    },
    {
      "epoch": 0.508578923418721,
      "grad_norm": 0.12932276725769043,
      "learning_rate": 1.796659439492492e-05,
      "loss": 0.037,
      "step": 38000
    },
    {
      "epoch": 0.515270751358441,
      "grad_norm": 0.0034719156101346016,
      "learning_rate": 1.793982708316604e-05,
      "loss": 0.0275,
      "step": 38500
    },
    {
      "epoch": 0.521962579298161,
      "grad_norm": 1.3697911500930786,
      "learning_rate": 1.791305977140716e-05,
      "loss": 0.0359,
      "step": 39000
    },
    {
      "epoch": 0.5286544072378812,
      "grad_norm": 0.03641897067427635,
      "learning_rate": 1.788629245964828e-05,
      "loss": 0.0314,
      "step": 39500
    },
    {
      "epoch": 0.5353462351776012,
      "grad_norm": 0.07218953222036362,
      "learning_rate": 1.7859525147889397e-05,
      "loss": 0.0354,
      "step": 40000
    },
    {
      "epoch": 0.5420380631173212,
      "grad_norm": 0.0013539899373427033,
      "learning_rate": 1.783281137075404e-05,
      "loss": 0.0323,
      "step": 40500
    },
    {
      "epoch": 0.5487298910570412,
      "grad_norm": 0.007444677408784628,
      "learning_rate": 1.7806044058995156e-05,
      "loss": 0.0317,
      "step": 41000
    },
    {
      "epoch": 0.5554217189967612,
      "grad_norm": 0.09833970665931702,
      "learning_rate": 1.7779276747236276e-05,
      "loss": 0.0364,
      "step": 41500
    },
    {
      "epoch": 0.5621135469364812,
      "grad_norm": 0.008745625615119934,
      "learning_rate": 1.7752509435477397e-05,
      "loss": 0.0219,
      "step": 42000
    },
    {
      "epoch": 0.5688053748762012,
      "grad_norm": 0.013100198470056057,
      "learning_rate": 1.7725742123718517e-05,
      "loss": 0.045,
      "step": 42500
    },
    {
      "epoch": 0.5754972028159212,
      "grad_norm": 0.009543226100504398,
      "learning_rate": 1.7698974811959637e-05,
      "loss": 0.0338,
      "step": 43000
    },
    {
      "epoch": 0.5821890307556412,
      "grad_norm": 0.154267355799675,
      "learning_rate": 1.7672261034824272e-05,
      "loss": 0.0485,
      "step": 43500
    },
    {
      "epoch": 0.5888808586953612,
      "grad_norm": 0.00789195578545332,
      "learning_rate": 1.764554725768891e-05,
      "loss": 0.0528,
      "step": 44000
    },
    {
      "epoch": 0.5955726866350812,
      "grad_norm": 0.004760543815791607,
      "learning_rate": 1.761877994593003e-05,
      "loss": 0.0335,
      "step": 44500
    },
    {
      "epoch": 0.6022645145748012,
      "grad_norm": 0.006895027589052916,
      "learning_rate": 1.759201263417115e-05,
      "loss": 0.0385,
      "step": 45000
    },
    {
      "epoch": 0.6089563425145212,
      "grad_norm": 29.424293518066406,
      "learning_rate": 1.7565245322412272e-05,
      "loss": 0.0975,
      "step": 45500
    },
    {
      "epoch": 0.6156481704542413,
      "grad_norm": 0.14066633582115173,
      "learning_rate": 1.7538478010653392e-05,
      "loss": 0.0401,
      "step": 46000
    },
    {
      "epoch": 0.6223399983939613,
      "grad_norm": 11.78432559967041,
      "learning_rate": 1.751171069889451e-05,
      "loss": 0.034,
      "step": 46500
    },
    {
      "epoch": 0.6290318263336813,
      "grad_norm": 3.980072021484375,
      "learning_rate": 1.748494338713563e-05,
      "loss": 0.0352,
      "step": 47000
    },
    {
      "epoch": 0.6357236542734013,
      "grad_norm": 0.005017422139644623,
      "learning_rate": 1.7458176075376753e-05,
      "loss": 0.0367,
      "step": 47500
    },
    {
      "epoch": 0.6424154822131214,
      "grad_norm": 0.018190061673521996,
      "learning_rate": 1.7431408763617873e-05,
      "loss": 0.0455,
      "step": 48000
    },
    {
      "epoch": 0.6491073101528414,
      "grad_norm": 0.0690702423453331,
      "learning_rate": 1.740469498648251e-05,
      "loss": 0.0439,
      "step": 48500
    },
    {
      "epoch": 0.6557991380925614,
      "grad_norm": 0.02622833661735058,
      "learning_rate": 1.737792767472363e-05,
      "loss": 0.0534,
      "step": 49000
    },
    {
      "epoch": 0.6624909660322814,
      "grad_norm": 0.007410981692373753,
      "learning_rate": 1.7351213897588268e-05,
      "loss": 0.0565,
      "step": 49500
    },
    {
      "epoch": 0.6691827939720014,
      "grad_norm": 0.023615024983882904,
      "learning_rate": 1.7324446585829388e-05,
      "loss": 0.0303,
      "step": 50000
    },
    {
      "epoch": 0.6758746219117214,
      "grad_norm": 25.32433319091797,
      "learning_rate": 1.7297732808694023e-05,
      "loss": 0.0354,
      "step": 50500
    },
    {
      "epoch": 0.6825664498514414,
      "grad_norm": 0.016241949051618576,
      "learning_rate": 1.7270965496935144e-05,
      "loss": 0.0522,
      "step": 51000
    },
    {
      "epoch": 0.6892582777911614,
      "grad_norm": 0.02320280112326145,
      "learning_rate": 1.7244198185176264e-05,
      "loss": 0.0315,
      "step": 51500
    },
    {
      "epoch": 0.6959501057308815,
      "grad_norm": 0.14172767102718353,
      "learning_rate": 1.7217430873417384e-05,
      "loss": 0.0361,
      "step": 52000
    },
    {
      "epoch": 0.7026419336706015,
      "grad_norm": 0.0428684763610363,
      "learning_rate": 1.7190663561658504e-05,
      "loss": 0.0504,
      "step": 52500
    },
    {
      "epoch": 0.7093337616103215,
      "grad_norm": 0.006326210219413042,
      "learning_rate": 1.7163896249899625e-05,
      "loss": 0.0396,
      "step": 53000
    },
    {
      "epoch": 0.7160255895500415,
      "grad_norm": 0.006577476859092712,
      "learning_rate": 1.7137128938140745e-05,
      "loss": 0.0414,
      "step": 53500
    },
    {
      "epoch": 0.7227174174897615,
      "grad_norm": 0.005494531709700823,
      "learning_rate": 1.7110415161005384e-05,
      "loss": 0.0397,
      "step": 54000
    },
    {
      "epoch": 0.7294092454294815,
      "grad_norm": 0.051431700587272644,
      "learning_rate": 1.708370138387002e-05,
      "loss": 0.0369,
      "step": 54500
    },
    {
      "epoch": 0.7361010733692015,
      "grad_norm": 0.03829536586999893,
      "learning_rate": 1.705693407211114e-05,
      "loss": 0.0581,
      "step": 55000
    },
    {
      "epoch": 0.7427929013089215,
      "grad_norm": 0.015044815838336945,
      "learning_rate": 1.703016676035226e-05,
      "loss": 0.0415,
      "step": 55500
    },
    {
      "epoch": 0.7494847292486415,
      "grad_norm": 0.024291738867759705,
      "learning_rate": 1.700339944859338e-05,
      "loss": 0.0393,
      "step": 56000
    },
    {
      "epoch": 0.7561765571883615,
      "grad_norm": 0.008540622889995575,
      "learning_rate": 1.69766321368345e-05,
      "loss": 0.0343,
      "step": 56500
    },
    {
      "epoch": 0.7628683851280816,
      "grad_norm": 0.040114279836416245,
      "learning_rate": 1.694986482507562e-05,
      "loss": 0.0434,
      "step": 57000
    },
    {
      "epoch": 0.7695602130678016,
      "grad_norm": 0.015358100645244122,
      "learning_rate": 1.692309751331674e-05,
      "loss": 0.0392,
      "step": 57500
    },
    {
      "epoch": 0.7762520410075217,
      "grad_norm": 4.507519245147705,
      "learning_rate": 1.6896330201557858e-05,
      "loss": 0.0288,
      "step": 58000
    },
    {
      "epoch": 0.7829438689472417,
      "grad_norm": 0.007302429527044296,
      "learning_rate": 1.6869562889798978e-05,
      "loss": 0.037,
      "step": 58500
    },
    {
      "epoch": 0.7896356968869617,
      "grad_norm": 0.027282489463686943,
      "learning_rate": 1.6842795578040098e-05,
      "loss": 0.0505,
      "step": 59000
    },
    {
      "epoch": 0.7963275248266817,
      "grad_norm": 0.0435088686645031,
      "learning_rate": 1.681602826628122e-05,
      "loss": 0.0372,
      "step": 59500
    },
    {
      "epoch": 0.8030193527664017,
      "grad_norm": 0.004382804036140442,
      "learning_rate": 1.678926095452234e-05,
      "loss": 0.041,
      "step": 60000
    },
    {
      "epoch": 0.8097111807061217,
      "grad_norm": 0.0889260470867157,
      "learning_rate": 1.676249364276346e-05,
      "loss": 0.0392,
      "step": 60500
    },
    {
      "epoch": 0.8164030086458417,
      "grad_norm": 0.6129966974258423,
      "learning_rate": 1.673572633100458e-05,
      "loss": 0.0457,
      "step": 61000
    },
    {
      "epoch": 0.8230948365855617,
      "grad_norm": 0.12050234526395798,
      "learning_rate": 1.67089590192457e-05,
      "loss": 0.0393,
      "step": 61500
    },
    {
      "epoch": 0.8297866645252817,
      "grad_norm": 0.023022426292300224,
      "learning_rate": 1.6682245242110335e-05,
      "loss": 0.0381,
      "step": 62000
    },
    {
      "epoch": 0.8364784924650017,
      "grad_norm": 0.12084700167179108,
      "learning_rate": 1.6655477930351455e-05,
      "loss": 0.04,
      "step": 62500
    },
    {
      "epoch": 0.8431703204047217,
      "grad_norm": 0.06323599070310593,
      "learning_rate": 1.6628764153216094e-05,
      "loss": 0.0464,
      "step": 63000
    },
    {
      "epoch": 0.8498621483444417,
      "grad_norm": 0.056267641484737396,
      "learning_rate": 1.6601996841457214e-05,
      "loss": 0.0309,
      "step": 63500
    },
    {
      "epoch": 0.8565539762841617,
      "grad_norm": 0.13685142993927002,
      "learning_rate": 1.6575229529698335e-05,
      "loss": 0.0382,
      "step": 64000
    },
    {
      "epoch": 0.8632458042238818,
      "grad_norm": 0.01324182003736496,
      "learning_rate": 1.6548462217939455e-05,
      "loss": 0.048,
      "step": 64500
    },
    {
      "epoch": 0.8699376321636018,
      "grad_norm": 25.4251766204834,
      "learning_rate": 1.652174844080409e-05,
      "loss": 0.0622,
      "step": 65000
    },
    {
      "epoch": 0.8766294601033219,
      "grad_norm": 0.019407005980610847,
      "learning_rate": 1.649498112904521e-05,
      "loss": 0.034,
      "step": 65500
    },
    {
      "epoch": 0.8833212880430419,
      "grad_norm": 0.013158817775547504,
      "learning_rate": 1.646821381728633e-05,
      "loss": 0.04,
      "step": 66000
    },
    {
      "epoch": 0.8900131159827619,
      "grad_norm": 0.022213362157344818,
      "learning_rate": 1.644144650552745e-05,
      "loss": 0.0424,
      "step": 66500
    },
    {
      "epoch": 0.8967049439224819,
      "grad_norm": 0.016293920576572418,
      "learning_rate": 1.641467919376857e-05,
      "loss": 0.0441,
      "step": 67000
    },
    {
      "epoch": 0.9033967718622019,
      "grad_norm": 0.11932259798049927,
      "learning_rate": 1.6387911882009692e-05,
      "loss": 0.0444,
      "step": 67500
    },
    {
      "epoch": 0.9100885998019219,
      "grad_norm": 0.03209853172302246,
      "learning_rate": 1.636119810487433e-05,
      "loss": 0.0358,
      "step": 68000
    },
    {
      "epoch": 0.9167804277416419,
      "grad_norm": 0.03486077859997749,
      "learning_rate": 1.6334430793115447e-05,
      "loss": 0.0389,
      "step": 68500
    },
    {
      "epoch": 0.9234722556813619,
      "grad_norm": 0.015240680426359177,
      "learning_rate": 1.6307663481356568e-05,
      "loss": 0.0446,
      "step": 69000
    },
    {
      "epoch": 0.9301640836210819,
      "grad_norm": 0.015254886820912361,
      "learning_rate": 1.6280896169597688e-05,
      "loss": 0.0682,
      "step": 69500
    },
    {
      "epoch": 0.936855911560802,
      "grad_norm": 3.8672003746032715,
      "learning_rate": 1.6254128857838808e-05,
      "loss": 0.0895,
      "step": 70000
    },
    {
      "epoch": 0.943547739500522,
      "grad_norm": 42.00361633300781,
      "learning_rate": 1.622736154607993e-05,
      "loss": 0.0785,
      "step": 70500
    },
    {
      "epoch": 0.950239567440242,
      "grad_norm": 0.017758021131157875,
      "learning_rate": 1.620059423432105e-05,
      "loss": 0.0711,
      "step": 71000
    },
    {
      "epoch": 0.956931395379962,
      "grad_norm": 0.020184917375445366,
      "learning_rate": 1.617382692256217e-05,
      "loss": 0.0543,
      "step": 71500
    },
    {
      "epoch": 0.963623223319682,
      "grad_norm": 0.018102100118994713,
      "learning_rate": 1.614705961080329e-05,
      "loss": 0.0491,
      "step": 72000
    },
    {
      "epoch": 0.970315051259402,
      "grad_norm": 0.02041660249233246,
      "learning_rate": 1.612029229904441e-05,
      "loss": 0.0601,
      "step": 72500
    },
    {
      "epoch": 0.977006879199122,
      "grad_norm": 0.016586367040872574,
      "learning_rate": 1.609352498728553e-05,
      "loss": 0.0468,
      "step": 73000
    },
    {
      "epoch": 0.983698707138842,
      "grad_norm": 0.010597994551062584,
      "learning_rate": 1.6066757675526647e-05,
      "loss": 0.0299,
      "step": 73500
    },
    {
      "epoch": 0.990390535078562,
      "grad_norm": 0.033980842679739,
      "learning_rate": 1.6039990363767767e-05,
      "loss": 0.0607,
      "step": 74000
    },
    {
      "epoch": 0.9970823630182821,
      "grad_norm": 0.016405552625656128,
      "learning_rate": 1.6013276586632406e-05,
      "loss": 0.0406,
      "step": 74500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9840065312240691,
      "eval_loss": 0.07214654982089996,
      "eval_runtime": 143.2855,
      "eval_samples_per_second": 521.462,
      "eval_steps_per_second": 65.185,
      "step": 74718
    }
  ],
  "logging_steps": 500,
  "max_steps": 373590,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.862333478479376e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
