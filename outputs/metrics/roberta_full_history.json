[
  {
    "loss": 0.1513,
    "grad_norm": 0.10677951574325562,
    "learning_rate": 1.9973286222864637e-05,
    "epoch": 0.006691827939720014,
    "step": 500
  },
  {
    "loss": 0.1372,
    "grad_norm": 0.21646328270435333,
    "learning_rate": 1.9946625980352794e-05,
    "epoch": 0.013383655879440027,
    "step": 1000
  },
  {
    "loss": 0.1491,
    "grad_norm": 0.18818466365337372,
    "learning_rate": 1.9919858668593914e-05,
    "epoch": 0.020075483819160043,
    "step": 1500
  },
  {
    "loss": 0.1548,
    "grad_norm": 0.18178687989711761,
    "learning_rate": 1.9893091356835034e-05,
    "epoch": 0.026767311758880055,
    "step": 2000
  },
  {
    "loss": 0.1407,
    "grad_norm": 2.6553702354431152,
    "learning_rate": 1.9866324045076155e-05,
    "epoch": 0.03345913969860007,
    "step": 2500
  },
  {
    "loss": 0.1245,
    "grad_norm": 0.07472965866327286,
    "learning_rate": 1.9839556733317275e-05,
    "epoch": 0.04015096763832009,
    "step": 3000
  },
  {
    "loss": 0.1162,
    "grad_norm": 0.06515845656394958,
    "learning_rate": 1.9812789421558395e-05,
    "epoch": 0.046842795578040095,
    "step": 3500
  },
  {
    "loss": 0.1494,
    "grad_norm": 0.23365165293216705,
    "learning_rate": 1.9786075644423034e-05,
    "epoch": 0.05353462351776011,
    "step": 4000
  },
  {
    "loss": 0.1236,
    "grad_norm": 2.867438554763794,
    "learning_rate": 1.975930833266415e-05,
    "epoch": 0.060226451457480124,
    "step": 4500
  },
  {
    "loss": 0.1411,
    "grad_norm": 0.18182700872421265,
    "learning_rate": 1.973254102090527e-05,
    "epoch": 0.06691827939720014,
    "step": 5000
  },
  {
    "loss": 0.1299,
    "grad_norm": 0.1370735466480255,
    "learning_rate": 1.970577370914639e-05,
    "epoch": 0.07361010733692015,
    "step": 5500
  },
  {
    "loss": 0.1466,
    "grad_norm": 0.2795925438404083,
    "learning_rate": 1.9679006397387512e-05,
    "epoch": 0.08030193527664017,
    "step": 6000
  },
  {
    "loss": 0.1343,
    "grad_norm": 0.1653769165277481,
    "learning_rate": 1.9652239085628632e-05,
    "epoch": 0.08699376321636018,
    "step": 6500
  },
  {
    "loss": 0.132,
    "grad_norm": 0.21104754507541656,
    "learning_rate": 1.9625471773869752e-05,
    "epoch": 0.09368559115608019,
    "step": 7000
  },
  {
    "loss": 0.1271,
    "grad_norm": 3.0221657752990723,
    "learning_rate": 1.9598704462110873e-05,
    "epoch": 0.10037741909580021,
    "step": 7500
  },
  {
    "loss": 0.1311,
    "grad_norm": 0.2373809814453125,
    "learning_rate": 1.9571937150351993e-05,
    "epoch": 0.10706924703552022,
    "step": 8000
  },
  {
    "loss": 0.1525,
    "grad_norm": 0.3785891830921173,
    "learning_rate": 1.9545169838593113e-05,
    "epoch": 0.11376107497524024,
    "step": 8500
  },
  {
    "loss": 0.1411,
    "grad_norm": 0.46640825271606445,
    "learning_rate": 1.9518402526834234e-05,
    "epoch": 0.12045290291496025,
    "step": 9000
  },
  {
    "loss": 0.1664,
    "grad_norm": 0.38307279348373413,
    "learning_rate": 1.949163521507535e-05,
    "epoch": 0.12714473085468025,
    "step": 9500
  },
  {
    "loss": 0.1481,
    "grad_norm": 0.22291815280914307,
    "learning_rate": 1.946486790331647e-05,
    "epoch": 0.1338365587944003,
    "step": 10000
  },
  {
    "loss": 0.1465,
    "grad_norm": 0.4102155864238739,
    "learning_rate": 1.943810059155759e-05,
    "epoch": 0.1405283867341203,
    "step": 10500
  },
  {
    "loss": 0.145,
    "grad_norm": 0.22693587839603424,
    "learning_rate": 1.941133327979871e-05,
    "epoch": 0.1472202146738403,
    "step": 11000
  },
  {
    "loss": 0.132,
    "grad_norm": 2.879465341567993,
    "learning_rate": 1.9384565968039832e-05,
    "epoch": 0.1539120426135603,
    "step": 11500
  },
  {
    "loss": 0.1418,
    "grad_norm": 2.8597936630249023,
    "learning_rate": 1.935785219090447e-05,
    "epoch": 0.16060387055328035,
    "step": 12000
  },
  {
    "loss": 0.1412,
    "grad_norm": 0.17003720998764038,
    "learning_rate": 1.933108487914559e-05,
    "epoch": 0.16729569849300036,
    "step": 12500
  },
  {
    "loss": 0.1605,
    "grad_norm": 0.3100828528404236,
    "learning_rate": 1.9304371102010226e-05,
    "epoch": 0.17398752643272036,
    "step": 13000
  },
  {
    "loss": 0.1527,
    "grad_norm": 0.36185240745544434,
    "learning_rate": 1.9277603790251346e-05,
    "epoch": 0.18067935437244037,
    "step": 13500
  },
  {
    "loss": 0.1457,
    "grad_norm": 0.26036179065704346,
    "learning_rate": 1.9250836478492467e-05,
    "epoch": 0.18737118231216038,
    "step": 14000
  },
  {
    "loss": 0.1312,
    "grad_norm": 0.2190120816230774,
    "learning_rate": 1.9224069166733587e-05,
    "epoch": 0.1940630102518804,
    "step": 14500
  },
  {
    "loss": 0.139,
    "grad_norm": 0.20768171548843384,
    "learning_rate": 1.9197301854974707e-05,
    "epoch": 0.20075483819160042,
    "step": 15000
  },
  {
    "loss": 0.1435,
    "grad_norm": 2.937957525253296,
    "learning_rate": 1.9170534543215828e-05,
    "epoch": 0.20744666613132043,
    "step": 15500
  },
  {
    "loss": 0.1377,
    "grad_norm": 2.9283008575439453,
    "learning_rate": 1.9143767231456948e-05,
    "epoch": 0.21413849407104044,
    "step": 16000
  },
  {
    "loss": 0.1459,
    "grad_norm": 2.894190788269043,
    "learning_rate": 1.9116999919698068e-05,
    "epoch": 0.22083032201076047,
    "step": 16500
  },
  {
    "loss": 0.1351,
    "grad_norm": 2.9491024017333984,
    "learning_rate": 1.9090286142562703e-05,
    "epoch": 0.22752214995048048,
    "step": 17000
  },
  {
    "loss": 0.1463,
    "grad_norm": 0.1970941126346588,
    "learning_rate": 1.9063518830803824e-05,
    "epoch": 0.2342139778902005,
    "step": 17500
  },
  {
    "loss": 0.1532,
    "grad_norm": 2.8435964584350586,
    "learning_rate": 1.9036751519044944e-05,
    "epoch": 0.2409058058299205,
    "step": 18000
  },
  {
    "loss": 0.1468,
    "grad_norm": 0.1818181425333023,
    "learning_rate": 1.9009984207286064e-05,
    "epoch": 0.2475976337696405,
    "step": 18500
  },
  {
    "loss": 0.131,
    "grad_norm": 0.20571865141391754,
    "learning_rate": 1.8983270430150703e-05,
    "epoch": 0.2542894617093605,
    "step": 19000
  },
  {
    "loss": 0.1416,
    "grad_norm": 0.25622209906578064,
    "learning_rate": 1.8956503118391823e-05,
    "epoch": 0.2609812896490805,
    "step": 19500
  },
  {
    "loss": 0.1571,
    "grad_norm": 2.9354257583618164,
    "learning_rate": 1.892973580663294e-05,
    "epoch": 0.2676731175888006,
    "step": 20000
  },
  {
    "loss": 0.1494,
    "grad_norm": 2.945683479309082,
    "learning_rate": 1.890296849487406e-05,
    "epoch": 0.2743649455285206,
    "step": 20500
  },
  {
    "loss": 0.1489,
    "grad_norm": 0.2448205053806305,
    "learning_rate": 1.88762547177387e-05,
    "epoch": 0.2810567734682406,
    "step": 21000
  },
  {
    "loss": 0.1381,
    "grad_norm": 2.98471999168396,
    "learning_rate": 1.884948740597982e-05,
    "epoch": 0.2877486014079606,
    "step": 21500
  },
  {
    "loss": 0.1376,
    "grad_norm": 0.15796050429344177,
    "learning_rate": 1.882272009422094e-05,
    "epoch": 0.2944404293476806,
    "step": 22000
  },
  {
    "loss": 0.1462,
    "grad_norm": 0.18203094601631165,
    "learning_rate": 1.879595278246206e-05,
    "epoch": 0.3011322572874006,
    "step": 22500
  },
  {
    "loss": 0.1467,
    "grad_norm": 2.9883058071136475,
    "learning_rate": 1.8769239005326695e-05,
    "epoch": 0.3078240852271206,
    "step": 23000
  },
  {
    "loss": 0.1403,
    "grad_norm": 0.3376384675502777,
    "learning_rate": 1.8742471693567816e-05,
    "epoch": 0.31451591316684063,
    "step": 23500
  },
  {
    "loss": 0.1451,
    "grad_norm": 0.3067972660064697,
    "learning_rate": 1.8715704381808936e-05,
    "epoch": 0.3212077411065607,
    "step": 24000
  },
  {
    "loss": 0.1364,
    "grad_norm": 0.2915654182434082,
    "learning_rate": 1.8688937070050056e-05,
    "epoch": 0.3278995690462807,
    "step": 24500
  },
  {
    "loss": 0.1336,
    "grad_norm": 0.18481393158435822,
    "learning_rate": 1.8662223292914695e-05,
    "epoch": 0.3345913969860007,
    "step": 25000
  },
  {
    "loss": 0.1355,
    "grad_norm": 0.17500625550746918,
    "learning_rate": 1.8635455981155815e-05,
    "epoch": 0.3412832249257207,
    "step": 25500
  },
  {
    "loss": 0.14,
    "grad_norm": 0.25824645161628723,
    "learning_rate": 1.8608688669396935e-05,
    "epoch": 0.3479750528654407,
    "step": 26000
  },
  {
    "loss": 0.1422,
    "grad_norm": 0.19331783056259155,
    "learning_rate": 1.858229610000268e-05,
    "epoch": 0.35466688080516073,
    "step": 26500
  },
  {
    "loss": 0.1516,
    "grad_norm": 0.26258033514022827,
    "learning_rate": 1.8555528788243798e-05,
    "epoch": 0.36135870874488074,
    "step": 27000
  },
  {
    "loss": 0.1291,
    "grad_norm": 0.1612614244222641,
    "learning_rate": 1.8528761476484918e-05,
    "epoch": 0.36805053668460075,
    "step": 27500
  },
  {
    "loss": 0.1337,
    "grad_norm": 0.21745245158672333,
    "learning_rate": 1.8501994164726038e-05,
    "epoch": 0.37474236462432076,
    "step": 28000
  },
  {
    "loss": 0.1492,
    "grad_norm": 0.19006098806858063,
    "learning_rate": 1.847522685296716e-05,
    "epoch": 0.3814341925640408,
    "step": 28500
  },
  {
    "loss": 0.1477,
    "grad_norm": 0.2318429946899414,
    "learning_rate": 1.844845954120828e-05,
    "epoch": 0.3881260205037608,
    "step": 29000
  },
  {
    "loss": 0.1389,
    "grad_norm": 0.24272821843624115,
    "learning_rate": 1.8421692229449396e-05,
    "epoch": 0.39481784844348083,
    "step": 29500
  },
  {
    "loss": 0.1282,
    "grad_norm": 0.15330570936203003,
    "learning_rate": 1.8394924917690516e-05,
    "epoch": 0.40150967638320084,
    "step": 30000
  },
  {
    "loss": 0.1644,
    "grad_norm": 0.19165192544460297,
    "learning_rate": 1.8368157605931636e-05,
    "epoch": 0.40820150432292085,
    "step": 30500
  },
  {
    "loss": 0.1348,
    "grad_norm": 0.23194167017936707,
    "learning_rate": 1.834139029417276e-05,
    "epoch": 0.41489333226264086,
    "step": 31000
  },
  {
    "loss": 0.1391,
    "grad_norm": 3.093334197998047,
    "learning_rate": 1.8314622982413877e-05,
    "epoch": 0.42158516020236086,
    "step": 31500
  },
  {
    "loss": 0.1357,
    "grad_norm": 0.19149921834468842,
    "learning_rate": 1.8287855670654997e-05,
    "epoch": 0.42827698814208087,
    "step": 32000
  },
  {
    "loss": 0.1344,
    "grad_norm": 0.27961966395378113,
    "learning_rate": 1.8261088358896118e-05,
    "epoch": 0.4349688160818009,
    "step": 32500
  },
  {
    "loss": 0.1587,
    "grad_norm": 0.2843612730503082,
    "learning_rate": 1.8234321047137238e-05,
    "epoch": 0.44166064402152094,
    "step": 33000
  },
  {
    "loss": 0.1721,
    "grad_norm": 0.4182813763618469,
    "learning_rate": 1.8207553735378358e-05,
    "epoch": 0.44835247196124095,
    "step": 33500
  },
  {
    "loss": 0.1442,
    "grad_norm": 0.2820013463497162,
    "learning_rate": 1.8180786423619475e-05,
    "epoch": 0.45504429990096096,
    "step": 34000
  },
  {
    "loss": 0.1386,
    "grad_norm": 0.3379807472229004,
    "learning_rate": 1.8154019111860595e-05,
    "epoch": 0.46173612784068097,
    "step": 34500
  },
  {
    "loss": 0.1382,
    "grad_norm": 0.21771402657032013,
    "learning_rate": 1.8127251800101716e-05,
    "epoch": 0.468427955780401,
    "step": 35000
  },
  {
    "loss": 0.1485,
    "grad_norm": 0.23585020005702972,
    "learning_rate": 1.810048448834284e-05,
    "epoch": 0.475119783720121,
    "step": 35500
  },
  {
    "loss": 0.1606,
    "grad_norm": 0.25862589478492737,
    "learning_rate": 1.807371717658396e-05,
    "epoch": 0.481811611659841,
    "step": 36000
  },
  {
    "loss": 0.1476,
    "grad_norm": 0.18452498316764832,
    "learning_rate": 1.8046949864825077e-05,
    "epoch": 0.488503439599561,
    "step": 36500
  },
  {
    "loss": 0.1308,
    "grad_norm": 0.20809873938560486,
    "learning_rate": 1.8020182553066197e-05,
    "epoch": 0.495195267539281,
    "step": 37000
  },
  {
    "loss": 0.1317,
    "grad_norm": 0.2144121676683426,
    "learning_rate": 1.7993415241307317e-05,
    "epoch": 0.501887095479001,
    "step": 37500
  },
  {
    "loss": 0.1328,
    "grad_norm": 0.14641959965229034,
    "learning_rate": 1.7966647929548437e-05,
    "epoch": 0.508578923418721,
    "step": 38000
  },
  {
    "loss": 0.1306,
    "grad_norm": 0.2369716912508011,
    "learning_rate": 1.7939880617789558e-05,
    "epoch": 0.515270751358441,
    "step": 38500
  },
  {
    "loss": 0.1409,
    "grad_norm": 3.0727410316467285,
    "learning_rate": 1.7913113306030675e-05,
    "epoch": 0.521962579298161,
    "step": 39000
  },
  {
    "loss": 0.1468,
    "grad_norm": 0.2378503382205963,
    "learning_rate": 1.7886345994271795e-05,
    "epoch": 0.5286544072378812,
    "step": 39500
  },
  {
    "loss": 0.1337,
    "grad_norm": 3.0233821868896484,
    "learning_rate": 1.7859578682512915e-05,
    "epoch": 0.5353462351776012,
    "step": 40000
  },
  {
    "loss": 0.1374,
    "grad_norm": 0.3503337800502777,
    "learning_rate": 1.783281137075404e-05,
    "epoch": 0.5420380631173212,
    "step": 40500
  },
  {
    "loss": 0.1494,
    "grad_norm": 0.22386810183525085,
    "learning_rate": 1.7806044058995156e-05,
    "epoch": 0.5487298910570412,
    "step": 41000
  },
  {
    "loss": 0.1539,
    "grad_norm": 2.931663990020752,
    "learning_rate": 1.7779276747236276e-05,
    "epoch": 0.5554217189967612,
    "step": 41500
  },
  {
    "loss": 0.1492,
    "grad_norm": 0.24285490810871124,
    "learning_rate": 1.7752509435477397e-05,
    "epoch": 0.5621135469364812,
    "step": 42000
  },
  {
    "loss": 0.1587,
    "grad_norm": 0.24332015216350555,
    "learning_rate": 1.7725795658342032e-05,
    "epoch": 0.5688053748762012,
    "step": 42500
  },
  {
    "loss": 0.1429,
    "grad_norm": 0.1923660933971405,
    "learning_rate": 1.7699028346583152e-05,
    "epoch": 0.5754972028159212,
    "step": 43000
  },
  {
    "loss": 0.1271,
    "grad_norm": 3.1034398078918457,
    "learning_rate": 1.7672261034824272e-05,
    "epoch": 0.5821890307556412,
    "step": 43500
  },
  {
    "loss": 0.1492,
    "grad_norm": 0.3018460273742676,
    "learning_rate": 1.7645493723065396e-05,
    "epoch": 0.5888808586953612,
    "step": 44000
  },
  {
    "loss": 0.1335,
    "grad_norm": 0.2622474133968353,
    "learning_rate": 1.7618726411306516e-05,
    "epoch": 0.5955726866350812,
    "step": 44500
  },
  {
    "loss": 0.1414,
    "grad_norm": 0.2582860589027405,
    "learning_rate": 1.7591959099547633e-05,
    "epoch": 0.6022645145748012,
    "step": 45000
  },
  {
    "loss": 0.1413,
    "grad_norm": 3.1694648265838623,
    "learning_rate": 1.7565191787788754e-05,
    "epoch": 0.6089563425145212,
    "step": 45500
  },
  {
    "loss": 0.1395,
    "grad_norm": 0.30050140619277954,
    "learning_rate": 1.7538424476029874e-05,
    "epoch": 0.6156481704542413,
    "step": 46000
  },
  {
    "loss": 0.1347,
    "grad_norm": 3.190302848815918,
    "learning_rate": 1.751171069889451e-05,
    "epoch": 0.6223399983939613,
    "step": 46500
  },
  {
    "loss": 0.1321,
    "grad_norm": 0.20293870568275452,
    "learning_rate": 1.748494338713563e-05,
    "epoch": 0.6290318263336813,
    "step": 47000
  },
  {
    "loss": 0.1516,
    "grad_norm": 0.1947057694196701,
    "learning_rate": 1.7458176075376753e-05,
    "epoch": 0.6357236542734013,
    "step": 47500
  },
  {
    "loss": 0.1485,
    "grad_norm": 0.25857800245285034,
    "learning_rate": 1.7431408763617873e-05,
    "epoch": 0.6424154822131214,
    "step": 48000
  },
  {
    "loss": 0.1477,
    "grad_norm": 0.25808507204055786,
    "learning_rate": 1.740464145185899e-05,
    "epoch": 0.6491073101528414,
    "step": 48500
  },
  {
    "loss": 0.1784,
    "grad_norm": 0.35680675506591797,
    "learning_rate": 1.737792767472363e-05,
    "epoch": 0.6557991380925614,
    "step": 49000
  },
  {
    "loss": 0.1481,
    "grad_norm": 0.23134425282478333,
    "learning_rate": 1.735116036296475e-05,
    "epoch": 0.6624909660322814,
    "step": 49500
  },
  {
    "loss": 0.1498,
    "grad_norm": 3.1041486263275146,
    "learning_rate": 1.7324393051205866e-05,
    "epoch": 0.6691827939720014,
    "step": 50000
  },
  {
    "loss": 0.1275,
    "grad_norm": 3.1718735694885254,
    "learning_rate": 1.7297625739446987e-05,
    "epoch": 0.6758746219117214,
    "step": 50500
  },
  {
    "loss": 0.1469,
    "grad_norm": 0.28922000527381897,
    "learning_rate": 1.727091196231163e-05,
    "epoch": 0.6825664498514414,
    "step": 51000
  },
  {
    "loss": 0.143,
    "grad_norm": 0.295168936252594,
    "learning_rate": 1.7244144650552746e-05,
    "epoch": 0.6892582777911614,
    "step": 51500
  },
  {
    "loss": 0.1262,
    "grad_norm": 0.23428356647491455,
    "learning_rate": 1.7217377338793866e-05,
    "epoch": 0.6959501057308815,
    "step": 52000
  },
  {
    "loss": 0.1428,
    "grad_norm": 3.0176079273223877,
    "learning_rate": 1.7190610027034986e-05,
    "epoch": 0.7026419336706015,
    "step": 52500
  },
  {
    "loss": 0.1343,
    "grad_norm": 0.21616192162036896,
    "learning_rate": 1.7163896249899625e-05,
    "epoch": 0.7093337616103215,
    "step": 53000
  },
  {
    "loss": 0.1503,
    "grad_norm": 0.31454744935035706,
    "learning_rate": 1.7137128938140745e-05,
    "epoch": 0.7160255895500415,
    "step": 53500
  },
  {
    "loss": 0.1333,
    "grad_norm": 0.2795393764972687,
    "learning_rate": 1.7110361626381865e-05,
    "epoch": 0.7227174174897615,
    "step": 54000
  },
  {
    "loss": 0.1353,
    "grad_norm": 6.049685955047607,
    "learning_rate": 1.7083594314622986e-05,
    "epoch": 0.7294092454294815,
    "step": 54500
  },
  {
    "loss": 0.1363,
    "grad_norm": 0.1671036034822464,
    "learning_rate": 1.705688053748762e-05,
    "epoch": 0.7361010733692015,
    "step": 55000
  },
  {
    "loss": 0.1475,
    "grad_norm": 0.2938135266304016,
    "learning_rate": 1.703011322572874e-05,
    "epoch": 0.7427929013089215,
    "step": 55500
  },
  {
    "loss": 0.1463,
    "grad_norm": 0.2152165323495865,
    "learning_rate": 1.700334591396986e-05,
    "epoch": 0.7494847292486415,
    "step": 56000
  },
  {
    "loss": 0.1331,
    "grad_norm": 0.21423780918121338,
    "learning_rate": 1.6976578602210982e-05,
    "epoch": 0.7561765571883615,
    "step": 56500
  },
  {
    "loss": 0.1394,
    "grad_norm": 3.171008586883545,
    "learning_rate": 1.694986482507562e-05,
    "epoch": 0.7628683851280816,
    "step": 57000
  },
  {
    "loss": 0.1339,
    "grad_norm": 0.21880552172660828,
    "learning_rate": 1.692309751331674e-05,
    "epoch": 0.7695602130678016,
    "step": 57500
  },
  {
    "loss": 0.1322,
    "grad_norm": 0.21642684936523438,
    "learning_rate": 1.6896330201557858e-05,
    "epoch": 0.7762520410075217,
    "step": 58000
  },
  {
    "loss": 0.1372,
    "grad_norm": 0.2505752742290497,
    "learning_rate": 1.6869562889798978e-05,
    "epoch": 0.7829438689472417,
    "step": 58500
  },
  {
    "loss": 0.1382,
    "grad_norm": 0.20867742598056793,
    "learning_rate": 1.6842849112663617e-05,
    "epoch": 0.7896356968869617,
    "step": 59000
  },
  {
    "loss": 0.1472,
    "grad_norm": 0.21016520261764526,
    "learning_rate": 1.6816081800904737e-05,
    "epoch": 0.7963275248266817,
    "step": 59500
  },
  {
    "loss": 0.1483,
    "grad_norm": 0.25295525789260864,
    "learning_rate": 1.6789314489145857e-05,
    "epoch": 0.8030193527664017,
    "step": 60000
  },
  {
    "loss": 0.1418,
    "grad_norm": 0.21830213069915771,
    "learning_rate": 1.6762547177386978e-05,
    "epoch": 0.8097111807061217,
    "step": 60500
  },
  {
    "loss": 0.1536,
    "grad_norm": 0.21377862989902496,
    "learning_rate": 1.6735833400251613e-05,
    "epoch": 0.8164030086458417,
    "step": 61000
  },
  {
    "loss": 0.1612,
    "grad_norm": 0.2950739562511444,
    "learning_rate": 1.6709066088492733e-05,
    "epoch": 0.8230948365855617,
    "step": 61500
  },
  {
    "loss": 0.1469,
    "grad_norm": 0.25418829917907715,
    "learning_rate": 1.6682298776733853e-05,
    "epoch": 0.8297866645252817,
    "step": 62000
  },
  {
    "loss": 0.1429,
    "grad_norm": 0.2688404321670532,
    "learning_rate": 1.6655531464974974e-05,
    "epoch": 0.8364784924650017,
    "step": 62500
  },
  {
    "loss": 0.1356,
    "grad_norm": 0.19361354410648346,
    "learning_rate": 1.6628817687839612e-05,
    "epoch": 0.8431703204047217,
    "step": 63000
  },
  {
    "loss": 0.1216,
    "grad_norm": 0.15582594275474548,
    "learning_rate": 1.6602050376080733e-05,
    "epoch": 0.8498621483444417,
    "step": 63500
  },
  {
    "loss": 0.1387,
    "grad_norm": 3.1105539798736572,
    "learning_rate": 1.6575336598945368e-05,
    "epoch": 0.8565539762841617,
    "step": 64000
  },
  {
    "loss": 0.1343,
    "grad_norm": 0.26435109972953796,
    "learning_rate": 1.6548569287186488e-05,
    "epoch": 0.8632458042238818,
    "step": 64500
  },
  {
    "loss": 0.1349,
    "grad_norm": 0.27260977029800415,
    "learning_rate": 1.652180197542761e-05,
    "epoch": 0.8699376321636018,
    "step": 65000
  },
  {
    "loss": 0.1546,
    "grad_norm": 0.297493577003479,
    "learning_rate": 1.649503466366873e-05,
    "epoch": 0.8766294601033219,
    "step": 65500
  },
  {
    "loss": 0.1469,
    "grad_norm": 0.18775002658367157,
    "learning_rate": 1.646826735190985e-05,
    "epoch": 0.8833212880430419,
    "step": 66000
  },
  {
    "loss": 0.1466,
    "grad_norm": 0.25990650057792664,
    "learning_rate": 1.644150004015097e-05,
    "epoch": 0.8900131159827619,
    "step": 66500
  },
  {
    "loss": 0.1321,
    "grad_norm": 0.17615044116973877,
    "learning_rate": 1.641473272839209e-05,
    "epoch": 0.8967049439224819,
    "step": 67000
  },
  {
    "loss": 0.1746,
    "grad_norm": 0.3794197142124176,
    "learning_rate": 1.638796541663321e-05,
    "epoch": 0.9033967718622019,
    "step": 67500
  },
  {
    "loss": 0.1423,
    "grad_norm": 3.141261339187622,
    "learning_rate": 1.6361251639497845e-05,
    "epoch": 0.9100885998019219,
    "step": 68000
  },
  {
    "loss": 0.1311,
    "grad_norm": 0.19140852987766266,
    "learning_rate": 1.6334484327738966e-05,
    "epoch": 0.9167804277416419,
    "step": 68500
  },
  {
    "loss": 0.1355,
    "grad_norm": 0.21828772127628326,
    "learning_rate": 1.6307717015980086e-05,
    "epoch": 0.9234722556813619,
    "step": 69000
  },
  {
    "loss": 0.1532,
    "grad_norm": 0.20601241290569305,
    "learning_rate": 1.6280949704221206e-05,
    "epoch": 0.9301640836210819,
    "step": 69500
  },
  {
    "loss": 0.1681,
    "grad_norm": 3.0032100677490234,
    "learning_rate": 1.6254235927085845e-05,
    "epoch": 0.936855911560802,
    "step": 70000
  },
  {
    "loss": 0.1454,
    "grad_norm": 3.130842685699463,
    "learning_rate": 1.6227468615326965e-05,
    "epoch": 0.943547739500522,
    "step": 70500
  },
  {
    "loss": 0.1584,
    "grad_norm": 0.27938327193260193,
    "learning_rate": 1.6200701303568085e-05,
    "epoch": 0.950239567440242,
    "step": 71000
  },
  {
    "loss": 0.1537,
    "grad_norm": 0.2718188166618347,
    "learning_rate": 1.6173933991809202e-05,
    "epoch": 0.956931395379962,
    "step": 71500
  },
  {
    "loss": 0.1571,
    "grad_norm": 0.3564060628414154,
    "learning_rate": 1.614722021467384e-05,
    "epoch": 0.963623223319682,
    "step": 72000
  },
  {
    "loss": 0.1437,
    "grad_norm": 0.3124120533466339,
    "learning_rate": 1.612045290291496e-05,
    "epoch": 0.970315051259402,
    "step": 72500
  },
  {
    "loss": 0.1456,
    "grad_norm": 0.2636156380176544,
    "learning_rate": 1.609368559115608e-05,
    "epoch": 0.977006879199122,
    "step": 73000
  },
  {
    "loss": 0.1347,
    "grad_norm": 0.27167102694511414,
    "learning_rate": 1.6066918279397202e-05,
    "epoch": 0.983698707138842,
    "step": 73500
  },
  {
    "loss": 0.1491,
    "grad_norm": 0.23717644810676575,
    "learning_rate": 1.604020450226184e-05,
    "epoch": 0.990390535078562,
    "step": 74000
  },
  {
    "loss": 0.1446,
    "grad_norm": 0.31197452545166016,
    "learning_rate": 1.6013437190502957e-05,
    "epoch": 0.9970823630182821,
    "step": 74500
  },
  {
    "eval_loss": 0.1386205554008484,
    "eval_accuracy": 0.9714258946973955,
    "eval_runtime": 131.4058,
    "eval_samples_per_second": 568.605,
    "eval_steps_per_second": 71.078,
    "epoch": 1.0,
    "step": 74718
  },
  {
    "loss": 0.1428,
    "grad_norm": 0.19056951999664307,
    "learning_rate": 1.5986669878744078e-05,
    "epoch": 1.003774190958002,
    "step": 75000
  },
  {
    "loss": 0.1401,
    "grad_norm": 0.18638060986995697,
    "learning_rate": 1.5959902566985198e-05,
    "epoch": 1.0104660188977221,
    "step": 75500
  },
  {
    "loss": 0.1361,
    "grad_norm": 0.16742342710494995,
    "learning_rate": 1.5933188789849837e-05,
    "epoch": 1.017157846837442,
    "step": 76000
  },
  {
    "loss": 0.1482,
    "grad_norm": 0.2569521367549896,
    "learning_rate": 1.5906421478090957e-05,
    "epoch": 1.0238496747771622,
    "step": 76500
  },
  {
    "loss": 0.1389,
    "grad_norm": 0.21851253509521484,
    "learning_rate": 1.5879654166332077e-05,
    "epoch": 1.030541502716882,
    "step": 77000
  },
  {
    "loss": 0.1245,
    "grad_norm": 0.15855248272418976,
    "learning_rate": 1.5852886854573198e-05,
    "epoch": 1.0372333306566022,
    "step": 77500
  },
  {
    "loss": 0.1507,
    "grad_norm": 0.23477716743946075,
    "learning_rate": 1.5826173077437833e-05,
    "epoch": 1.043925158596322,
    "step": 78000
  },
  {
    "loss": 0.1325,
    "grad_norm": 0.20680205523967743,
    "learning_rate": 1.5799405765678953e-05,
    "epoch": 1.0506169865360422,
    "step": 78500
  },
  {
    "loss": 0.1558,
    "grad_norm": 3.075533390045166,
    "learning_rate": 1.5772638453920073e-05,
    "epoch": 1.0573088144757623,
    "step": 79000
  },
  {
    "loss": 0.1442,
    "grad_norm": 0.32076340913772583,
    "learning_rate": 1.5745871142161194e-05,
    "epoch": 1.0640006424154822,
    "step": 79500
  },
  {
    "loss": 0.1536,
    "grad_norm": 0.27577462792396545,
    "learning_rate": 1.5719103830402314e-05,
    "epoch": 1.0706924703552023,
    "step": 80000
  },
  {
    "loss": 0.1304,
    "grad_norm": 3.2287769317626953,
    "learning_rate": 1.5692390053266953e-05,
    "epoch": 1.0773842982949222,
    "step": 80500
  },
  {
    "loss": 0.1328,
    "grad_norm": 0.2338527888059616,
    "learning_rate": 1.566562274150807e-05,
    "epoch": 1.0840761262346423,
    "step": 81000
  },
  {
    "loss": 0.1595,
    "grad_norm": 0.25613030791282654,
    "learning_rate": 1.563885542974919e-05,
    "epoch": 1.0907679541743622,
    "step": 81500
  },
  {
    "loss": 0.1599,
    "grad_norm": 3.146104335784912,
    "learning_rate": 1.561208811799031e-05,
    "epoch": 1.0974597821140823,
    "step": 82000
  },
  {
    "loss": 0.1383,
    "grad_norm": 0.27772703766822815,
    "learning_rate": 1.558537434085495e-05,
    "epoch": 1.1041516100538022,
    "step": 82500
  },
  {
    "loss": 0.1621,
    "grad_norm": 3.041640281677246,
    "learning_rate": 1.555860702909607e-05,
    "epoch": 1.1108434379935224,
    "step": 83000
  },
  {
    "loss": 0.1266,
    "grad_norm": 3.257828712463379,
    "learning_rate": 1.553183971733719e-05,
    "epoch": 1.1175352659332423,
    "step": 83500
  },
  {
    "loss": 0.1422,
    "grad_norm": 0.2340235412120819,
    "learning_rate": 1.550507240557831e-05,
    "epoch": 1.1242270938729624,
    "step": 84000
  },
  {
    "loss": 0.1219,
    "grad_norm": 0.226969912648201,
    "learning_rate": 1.5478358628442945e-05,
    "epoch": 1.1309189218126823,
    "step": 84500
  },
  {
    "loss": 0.1447,
    "grad_norm": 0.20095491409301758,
    "learning_rate": 1.5451591316684065e-05,
    "epoch": 1.1376107497524024,
    "step": 85000
  },
  {
    "loss": 0.1161,
    "grad_norm": 3.2745156288146973,
    "learning_rate": 1.542482400492519e-05,
    "epoch": 1.1443025776921223,
    "step": 85500
  },
  {
    "loss": 0.1398,
    "grad_norm": 3.209043502807617,
    "learning_rate": 1.5398056693166306e-05,
    "epoch": 1.1509944056318424,
    "step": 86000
  },
  {
    "loss": 0.1452,
    "grad_norm": 6.414168357849121,
    "learning_rate": 1.5371342916030945e-05,
    "epoch": 1.1576862335715625,
    "step": 86500
  },
  {
    "loss": 0.1639,
    "grad_norm": 0.2476603239774704,
    "learning_rate": 1.5344575604272065e-05,
    "epoch": 1.1643780615112824,
    "step": 87000
  },
  {
    "loss": 0.1506,
    "grad_norm": 3.1699612140655518,
    "learning_rate": 1.5317808292513182e-05,
    "epoch": 1.1710698894510023,
    "step": 87500
  },
  {
    "loss": 0.155,
    "grad_norm": 0.2936290502548218,
    "learning_rate": 1.5291040980754302e-05,
    "epoch": 1.1777617173907224,
    "step": 88000
  },
  {
    "loss": 0.1309,
    "grad_norm": 3.182090997695923,
    "learning_rate": 1.5264327203618944e-05,
    "epoch": 1.1844535453304426,
    "step": 88500
  },
  {
    "loss": 0.1448,
    "grad_norm": 0.2568676471710205,
    "learning_rate": 1.5237559891860061e-05,
    "epoch": 1.1911453732701625,
    "step": 89000
  },
  {
    "loss": 0.1361,
    "grad_norm": 6.361003398895264,
    "learning_rate": 1.5210792580101181e-05,
    "epoch": 1.1978372012098826,
    "step": 89500
  },
  {
    "loss": 0.1486,
    "grad_norm": 0.29185014963150024,
    "learning_rate": 1.5184025268342302e-05,
    "epoch": 1.2045290291496025,
    "step": 90000
  },
  {
    "loss": 0.1381,
    "grad_norm": 0.20898497104644775,
    "learning_rate": 1.5157311491206939e-05,
    "epoch": 1.2112208570893226,
    "step": 90500
  },
  {
    "loss": 0.156,
    "grad_norm": 0.2685478627681732,
    "learning_rate": 1.5130544179448059e-05,
    "epoch": 1.2179126850290425,
    "step": 91000
  },
  {
    "loss": 0.1286,
    "grad_norm": 0.20960766077041626,
    "learning_rate": 1.510377686768918e-05,
    "epoch": 1.2246045129687626,
    "step": 91500
  },
  {
    "loss": 0.1452,
    "grad_norm": 0.27031221985816956,
    "learning_rate": 1.50770095559303e-05,
    "epoch": 1.2312963409084825,
    "step": 92000
  },
  {
    "loss": 0.1436,
    "grad_norm": 0.2509033977985382,
    "learning_rate": 1.5050295778794936e-05,
    "epoch": 1.2379881688482026,
    "step": 92500
  },
  {
    "loss": 0.1385,
    "grad_norm": 0.2061702013015747,
    "learning_rate": 1.5023528467036057e-05,
    "epoch": 1.2446799967879225,
    "step": 93000
  },
  {
    "loss": 0.1532,
    "grad_norm": 0.28864988684654236,
    "learning_rate": 1.4996761155277177e-05,
    "epoch": 1.2513718247276426,
    "step": 93500
  },
  {
    "loss": 0.1461,
    "grad_norm": 3.2489609718322754,
    "learning_rate": 1.4969993843518296e-05,
    "epoch": 1.2580636526673628,
    "step": 94000
  },
  {
    "loss": 0.144,
    "grad_norm": 0.21878105401992798,
    "learning_rate": 1.4943280066382934e-05,
    "epoch": 1.2647554806070826,
    "step": 94500
  },
  {
    "loss": 0.139,
    "grad_norm": 0.2862592041492462,
    "learning_rate": 1.4916512754624055e-05,
    "epoch": 1.2714473085468025,
    "step": 95000
  },
  {
    "loss": 0.1548,
    "grad_norm": 0.2809557318687439,
    "learning_rate": 1.4889745442865173e-05,
    "epoch": 1.2781391364865227,
    "step": 95500
  },
  {
    "loss": 0.1358,
    "grad_norm": 0.20968829095363617,
    "learning_rate": 1.4862978131106294e-05,
    "epoch": 1.2848309644262428,
    "step": 96000
  },
  {
    "loss": 0.1372,
    "grad_norm": 0.24055363237857819,
    "learning_rate": 1.4836264353970932e-05,
    "epoch": 1.2915227923659627,
    "step": 96500
  },
  {
    "loss": 0.1288,
    "grad_norm": 0.20155613124370575,
    "learning_rate": 1.480949704221205e-05,
    "epoch": 1.2982146203056826,
    "step": 97000
  },
  {
    "loss": 0.1404,
    "grad_norm": 0.20083636045455933,
    "learning_rate": 1.4782729730453171e-05,
    "epoch": 1.3049064482454027,
    "step": 97500
  },
  {
    "loss": 0.1324,
    "grad_norm": 0.19604173302650452,
    "learning_rate": 1.4755962418694291e-05,
    "epoch": 1.3115982761851228,
    "step": 98000
  },
  {
    "loss": 0.127,
    "grad_norm": Infinity,
    "learning_rate": 1.4729195106935412e-05,
    "epoch": 1.3182901041248427,
    "step": 98500
  },
  {
    "loss": 0.1393,
    "grad_norm": 0.25152331590652466,
    "learning_rate": 1.4702481329800049e-05,
    "epoch": 1.3249819320645628,
    "step": 99000
  },
  {
    "loss": 0.131,
    "grad_norm": 0.18336248397827148,
    "learning_rate": 1.4675714018041169e-05,
    "epoch": 1.3316737600042827,
    "step": 99500
  },
  {
    "loss": 0.1358,
    "grad_norm": 0.2659684419631958,
    "learning_rate": 1.464894670628229e-05,
    "epoch": 1.3383655879440028,
    "step": 100000
  },
  {
    "loss": 0.1324,
    "grad_norm": 0.20881037414073944,
    "learning_rate": 1.462217939452341e-05,
    "epoch": 1.3450574158837227,
    "step": 100500
  },
  {
    "loss": 0.1461,
    "grad_norm": 0.24382980167865753,
    "learning_rate": 1.4595465617388047e-05,
    "epoch": 1.3517492438234429,
    "step": 101000
  },
  {
    "loss": 0.1341,
    "grad_norm": 0.21145747601985931,
    "learning_rate": 1.4568698305629167e-05,
    "epoch": 1.3584410717631628,
    "step": 101500
  },
  {
    "loss": 0.1484,
    "grad_norm": 0.25964075326919556,
    "learning_rate": 1.4541930993870285e-05,
    "epoch": 1.3651328997028829,
    "step": 102000
  },
  {
    "loss": 0.1619,
    "grad_norm": 0.2407292127609253,
    "learning_rate": 1.4515163682111406e-05,
    "epoch": 1.3718247276426028,
    "step": 102500
  },
  {
    "loss": 0.1195,
    "grad_norm": 0.22983136773109436,
    "learning_rate": 1.4488449904976044e-05,
    "epoch": 1.3785165555823229,
    "step": 103000
  },
  {
    "loss": 0.1451,
    "grad_norm": 0.2389543056488037,
    "learning_rate": 1.4461682593217163e-05,
    "epoch": 1.385208383522043,
    "step": 103500
  },
  {
    "loss": 0.1494,
    "grad_norm": 0.30211159586906433,
    "learning_rate": 1.4434915281458283e-05,
    "epoch": 1.391900211461763,
    "step": 104000
  },
  {
    "loss": 0.1501,
    "grad_norm": 0.27601373195648193,
    "learning_rate": 1.4408147969699404e-05,
    "epoch": 1.3985920394014828,
    "step": 104500
  },
  {
    "loss": 0.1379,
    "grad_norm": 0.22514472901821136,
    "learning_rate": 1.438143419256404e-05,
    "epoch": 1.405283867341203,
    "step": 105000
  },
  {
    "loss": 0.1602,
    "grad_norm": 0.3383714258670807,
    "learning_rate": 1.435466688080516e-05,
    "epoch": 1.411975695280923,
    "step": 105500
  },
  {
    "loss": 0.1383,
    "grad_norm": 0.22368976473808289,
    "learning_rate": 1.4327899569046281e-05,
    "epoch": 1.418667523220643,
    "step": 106000
  },
  {
    "loss": 0.1354,
    "grad_norm": 0.20939287543296814,
    "learning_rate": 1.4301132257287403e-05,
    "epoch": 1.4253593511603628,
    "step": 106500
  },
  {
    "loss": 0.1406,
    "grad_norm": 0.25690463185310364,
    "learning_rate": 1.4274418480152038e-05,
    "epoch": 1.432051179100083,
    "step": 107000
  },
  {
    "loss": 0.1505,
    "grad_norm": 0.2727072238922119,
    "learning_rate": 1.424765116839316e-05,
    "epoch": 1.438743007039803,
    "step": 107500
  },
  {
    "loss": 0.1577,
    "grad_norm": 0.29457905888557434,
    "learning_rate": 1.422088385663428e-05,
    "epoch": 1.445434834979523,
    "step": 108000
  },
  {
    "loss": 0.1353,
    "grad_norm": 0.22443342208862305,
    "learning_rate": 1.4194116544875401e-05,
    "epoch": 1.452126662919243,
    "step": 108500
  },
  {
    "loss": 0.1457,
    "grad_norm": 3.1870694160461426,
    "learning_rate": 1.4167402767740038e-05,
    "epoch": 1.458818490858963,
    "step": 109000
  },
  {
    "loss": 0.1361,
    "grad_norm": 0.2499515563249588,
    "learning_rate": 1.4140635455981158e-05,
    "epoch": 1.465510318798683,
    "step": 109500
  },
  {
    "loss": 0.1719,
    "grad_norm": 3.170297622680664,
    "learning_rate": 1.4113868144222275e-05,
    "epoch": 1.472202146738403,
    "step": 110000
  },
  {
    "loss": 0.1412,
    "grad_norm": 0.20561963319778442,
    "learning_rate": 1.4087100832463395e-05,
    "epoch": 1.4788939746781231,
    "step": 110500
  },
  {
    "loss": 0.1503,
    "grad_norm": 3.2498724460601807,
    "learning_rate": 1.4060333520704517e-05,
    "epoch": 1.485585802617843,
    "step": 111000
  },
  {
    "loss": 0.134,
    "grad_norm": 3.2531189918518066,
    "learning_rate": 1.4033619743569153e-05,
    "epoch": 1.4922776305575631,
    "step": 111500
  },
  {
    "loss": 0.1358,
    "grad_norm": 3.2519214153289795,
    "learning_rate": 1.4006852431810275e-05,
    "epoch": 1.498969458497283,
    "step": 112000
  },
  {
    "loss": 0.1481,
    "grad_norm": 0.23003606498241425,
    "learning_rate": 1.3980085120051395e-05,
    "epoch": 1.5056612864370031,
    "step": 112500
  },
  {
    "loss": 0.1508,
    "grad_norm": 0.3203686773777008,
    "learning_rate": 1.3953317808292515e-05,
    "epoch": 1.5123531143767233,
    "step": 113000
  },
  {
    "loss": 0.1385,
    "grad_norm": 0.22559207677841187,
    "learning_rate": 1.3926604031157152e-05,
    "epoch": 1.5190449423164432,
    "step": 113500
  },
  {
    "loss": 0.152,
    "grad_norm": 0.2578751742839813,
    "learning_rate": 1.3899836719398273e-05,
    "epoch": 1.525736770256163,
    "step": 114000
  },
  {
    "loss": 0.1423,
    "grad_norm": 6.551958084106445,
    "learning_rate": 1.3873069407639393e-05,
    "epoch": 1.5324285981958832,
    "step": 114500
  },
  {
    "loss": 0.1435,
    "grad_norm": 0.21311070024967194,
    "learning_rate": 1.3846302095880513e-05,
    "epoch": 1.5391204261356033,
    "step": 115000
  },
  {
    "loss": 0.1496,
    "grad_norm": 0.25028541684150696,
    "learning_rate": 1.381958831874515e-05,
    "epoch": 1.5458122540753232,
    "step": 115500
  },
  {
    "loss": 0.166,
    "grad_norm": 0.28061443567276,
    "learning_rate": 1.379282100698627e-05,
    "epoch": 1.552504082015043,
    "step": 116000
  },
  {
    "loss": 0.1462,
    "grad_norm": 3.2752106189727783,
    "learning_rate": 1.376605369522739e-05,
    "epoch": 1.5591959099547632,
    "step": 116500
  },
  {
    "loss": 0.1516,
    "grad_norm": 0.2556989789009094,
    "learning_rate": 1.373928638346851e-05,
    "epoch": 1.5658877378944833,
    "step": 117000
  },
  {
    "loss": 0.1384,
    "grad_norm": 0.19832462072372437,
    "learning_rate": 1.3712572606333148e-05,
    "epoch": 1.5725795658342032,
    "step": 117500
  },
  {
    "loss": 0.1286,
    "grad_norm": 3.2097856998443604,
    "learning_rate": 1.3685805294574268e-05,
    "epoch": 1.5792713937739233,
    "step": 118000
  },
  {
    "loss": 0.1513,
    "grad_norm": 0.2324552834033966,
    "learning_rate": 1.3659037982815387e-05,
    "epoch": 1.5859632217136435,
    "step": 118500
  },
  {
    "loss": 0.1363,
    "grad_norm": 0.17440453171730042,
    "learning_rate": 1.3632270671056507e-05,
    "epoch": 1.5926550496533634,
    "step": 119000
  },
  {
    "loss": 0.1638,
    "grad_norm": 0.28939542174339294,
    "learning_rate": 1.3605556893921144e-05,
    "epoch": 1.5993468775930832,
    "step": 119500
  },
  {
    "loss": 0.1296,
    "grad_norm": 0.25278007984161377,
    "learning_rate": 1.3578789582162264e-05,
    "epoch": 1.6060387055328034,
    "step": 120000
  },
  {
    "loss": 0.136,
    "grad_norm": 0.24553030729293823,
    "learning_rate": 1.3552022270403385e-05,
    "epoch": 1.6127305334725235,
    "step": 120500
  },
  {
    "loss": 0.1224,
    "grad_norm": 0.16800230741500854,
    "learning_rate": 1.3525254958644505e-05,
    "epoch": 1.6194223614122434,
    "step": 121000
  },
  {
    "loss": 0.1328,
    "grad_norm": 0.23703335225582123,
    "learning_rate": 1.3498541181509142e-05,
    "epoch": 1.6261141893519633,
    "step": 121500
  },
  {
    "loss": 0.1516,
    "grad_norm": 0.2336115688085556,
    "learning_rate": 1.3471773869750262e-05,
    "epoch": 1.6328060172916834,
    "step": 122000
  },
  {
    "loss": 0.1423,
    "grad_norm": 0.22491055727005005,
    "learning_rate": 1.3445006557991383e-05,
    "epoch": 1.6394978452314035,
    "step": 122500
  },
  {
    "loss": 0.1327,
    "grad_norm": 0.17988421022891998,
    "learning_rate": 1.3418239246232503e-05,
    "epoch": 1.6461896731711234,
    "step": 123000
  },
  {
    "loss": 0.1498,
    "grad_norm": 0.2573433518409729,
    "learning_rate": 1.339152546909714e-05,
    "epoch": 1.6528815011108433,
    "step": 123500
  },
  {
    "loss": 0.161,
    "grad_norm": 0.26677045226097107,
    "learning_rate": 1.336475815733826e-05,
    "epoch": 1.6595733290505634,
    "step": 124000
  },
  {
    "loss": 0.146,
    "grad_norm": 0.250180184841156,
    "learning_rate": 1.333799084557938e-05,
    "epoch": 1.6662651569902835,
    "step": 124500
  },
  {
    "loss": 0.1471,
    "grad_norm": 0.227781742811203,
    "learning_rate": 1.3311223533820499e-05,
    "epoch": 1.6729569849300034,
    "step": 125000
  },
  {
    "loss": 0.151,
    "grad_norm": 0.22330588102340698,
    "learning_rate": 1.3284509756685138e-05,
    "epoch": 1.6796488128697233,
    "step": 125500
  },
  {
    "loss": 0.1342,
    "grad_norm": 0.20190078020095825,
    "learning_rate": 1.3257742444926258e-05,
    "epoch": 1.6863406408094435,
    "step": 126000
  },
  {
    "loss": 0.1348,
    "grad_norm": 0.2005687952041626,
    "learning_rate": 1.3230975133167377e-05,
    "epoch": 1.6930324687491636,
    "step": 126500
  },
  {
    "loss": 0.1386,
    "grad_norm": 0.26335594058036804,
    "learning_rate": 1.3204207821408497e-05,
    "epoch": 1.6997242966888835,
    "step": 127000
  },
  {
    "loss": 0.1488,
    "grad_norm": 0.267200231552124,
    "learning_rate": 1.3177494044273136e-05,
    "epoch": 1.7064161246286036,
    "step": 127500
  },
  {
    "loss": 0.1373,
    "grad_norm": 3.066711187362671,
    "learning_rate": 1.3150726732514254e-05,
    "epoch": 1.7131079525683237,
    "step": 128000
  },
  {
    "loss": 0.1526,
    "grad_norm": 0.31326398253440857,
    "learning_rate": 1.3123959420755374e-05,
    "epoch": 1.7197997805080436,
    "step": 128500
  },
  {
    "loss": 0.1498,
    "grad_norm": 0.2648293673992157,
    "learning_rate": 1.3097192108996495e-05,
    "epoch": 1.7264916084477635,
    "step": 129000
  },
  {
    "loss": 0.1486,
    "grad_norm": 0.20124858617782593,
    "learning_rate": 1.3070478331861132e-05,
    "epoch": 1.7331834363874836,
    "step": 129500
  },
  {
    "loss": 0.1546,
    "grad_norm": 0.27567774057388306,
    "learning_rate": 1.3043711020102252e-05,
    "epoch": 1.7398752643272037,
    "step": 130000
  },
  {
    "loss": 0.1584,
    "grad_norm": 0.3473474085330963,
    "learning_rate": 1.3016943708343372e-05,
    "epoch": 1.7465670922669236,
    "step": 130500
  },
  {
    "loss": 0.1515,
    "grad_norm": 0.2793840765953064,
    "learning_rate": 1.2990176396584493e-05,
    "epoch": 1.7532589202066435,
    "step": 131000
  },
  {
    "loss": 0.1412,
    "grad_norm": 0.246985524892807,
    "learning_rate": 1.296346261944913e-05,
    "epoch": 1.7599507481463637,
    "step": 131500
  },
  {
    "loss": 0.1592,
    "grad_norm": 0.3219636380672455,
    "learning_rate": 1.293669530769025e-05,
    "epoch": 1.7666425760860838,
    "step": 132000
  },
  {
    "loss": 0.1283,
    "grad_norm": 0.171405628323555,
    "learning_rate": 1.290992799593137e-05,
    "epoch": 1.7733344040258037,
    "step": 132500
  },
  {
    "loss": 0.1397,
    "grad_norm": 0.23735125362873077,
    "learning_rate": 1.2883160684172489e-05,
    "epoch": 1.7800262319655236,
    "step": 133000
  },
  {
    "loss": 0.1182,
    "grad_norm": 0.17998917400836945,
    "learning_rate": 1.2856393372413609e-05,
    "epoch": 1.7867180599052437,
    "step": 133500
  },
  {
    "loss": 0.1341,
    "grad_norm": 0.1784975677728653,
    "learning_rate": 1.2829679595278248e-05,
    "epoch": 1.7934098878449638,
    "step": 134000
  },
  {
    "loss": 0.1468,
    "grad_norm": 0.2471577674150467,
    "learning_rate": 1.2802912283519366e-05,
    "epoch": 1.8001017157846837,
    "step": 134500
  },
  {
    "loss": 0.1266,
    "grad_norm": 0.20610330998897552,
    "learning_rate": 1.2776144971760487e-05,
    "epoch": 1.8067935437244036,
    "step": 135000
  },
  {
    "loss": 0.1383,
    "grad_norm": 0.2039961814880371,
    "learning_rate": 1.2749377660001607e-05,
    "epoch": 1.813485371664124,
    "step": 135500
  },
  {
    "loss": 0.1466,
    "grad_norm": 2.9696412086486816,
    "learning_rate": 1.2722663882866244e-05,
    "epoch": 1.8201771996038438,
    "step": 136000
  },
  {
    "loss": 0.1557,
    "grad_norm": 0.24109648168087006,
    "learning_rate": 1.2695896571107364e-05,
    "epoch": 1.8268690275435637,
    "step": 136500
  },
  {
    "loss": 0.1525,
    "grad_norm": 6.249216556549072,
    "learning_rate": 1.2669129259348485e-05,
    "epoch": 1.8335608554832838,
    "step": 137000
  },
  {
    "loss": 0.1465,
    "grad_norm": 0.25923702120780945,
    "learning_rate": 1.2642361947589605e-05,
    "epoch": 1.840252683423004,
    "step": 137500
  },
  {
    "loss": 0.1523,
    "grad_norm": 0.250933438539505,
    "learning_rate": 1.2615648170454242e-05,
    "epoch": 1.8469445113627239,
    "step": 138000
  },
  {
    "loss": 0.1451,
    "grad_norm": 0.26386213302612305,
    "learning_rate": 1.2588934393318879e-05,
    "epoch": 1.8536363393024438,
    "step": 138500
  },
  {
    "loss": 0.1445,
    "grad_norm": 0.2515091896057129,
    "learning_rate": 1.2562167081559999e-05,
    "epoch": 1.8603281672421639,
    "step": 139000
  },
  {
    "loss": 0.1541,
    "grad_norm": 0.2444702684879303,
    "learning_rate": 1.253539976980112e-05,
    "epoch": 1.867019995181884,
    "step": 139500
  },
  {
    "loss": 0.1372,
    "grad_norm": 3.1767783164978027,
    "learning_rate": 1.250863245804224e-05,
    "epoch": 1.873711823121604,
    "step": 140000
  },
  {
    "loss": 0.1417,
    "grad_norm": 3.1129040718078613,
    "learning_rate": 1.248186514628336e-05,
    "epoch": 1.8804036510613238,
    "step": 140500
  },
  {
    "loss": 0.1386,
    "grad_norm": 0.24663792550563812,
    "learning_rate": 1.2455097834524479e-05,
    "epoch": 1.887095479001044,
    "step": 141000
  },
  {
    "loss": 0.1543,
    "grad_norm": 3.2019717693328857,
    "learning_rate": 1.2428330522765599e-05,
    "epoch": 1.893787306940764,
    "step": 141500
  },
  {
    "loss": 0.1328,
    "grad_norm": 0.2335873395204544,
    "learning_rate": 1.2401563211006719e-05,
    "epoch": 1.900479134880484,
    "step": 142000
  },
  {
    "loss": 0.1341,
    "grad_norm": 0.20136448740959167,
    "learning_rate": 1.2374849433871356e-05,
    "epoch": 1.9071709628202038,
    "step": 142500
  },
  {
    "loss": 0.156,
    "grad_norm": 0.21321024000644684,
    "learning_rate": 1.2348082122112476e-05,
    "epoch": 1.913862790759924,
    "step": 143000
  },
  {
    "loss": 0.1468,
    "grad_norm": 0.24556945264339447,
    "learning_rate": 1.2321314810353597e-05,
    "epoch": 1.920554618699644,
    "step": 143500
  },
  {
    "loss": 0.1403,
    "grad_norm": 0.26240700483322144,
    "learning_rate": 1.2294547498594717e-05,
    "epoch": 1.927246446639364,
    "step": 144000
  },
  {
    "loss": 0.1335,
    "grad_norm": 3.177061080932617,
    "learning_rate": 1.2267833721459354e-05,
    "epoch": 1.933938274579084,
    "step": 144500
  },
  {
    "loss": 0.1513,
    "grad_norm": 0.2773382365703583,
    "learning_rate": 1.2241066409700474e-05,
    "epoch": 1.9406301025188042,
    "step": 145000
  },
  {
    "loss": 0.1415,
    "grad_norm": 0.22068077325820923,
    "learning_rate": 1.2214299097941596e-05,
    "epoch": 1.947321930458524,
    "step": 145500
  },
  {
    "loss": 0.1413,
    "grad_norm": 0.2874789535999298,
    "learning_rate": 1.2187531786182713e-05,
    "epoch": 1.954013758398244,
    "step": 146000
  },
  {
    "loss": 0.1435,
    "grad_norm": 0.21718189120292664,
    "learning_rate": 1.2160818009047353e-05,
    "epoch": 1.960705586337964,
    "step": 146500
  },
  {
    "loss": 0.1456,
    "grad_norm": 0.27550798654556274,
    "learning_rate": 1.2134050697288474e-05,
    "epoch": 1.9673974142776842,
    "step": 147000
  },
  {
    "loss": 0.1447,
    "grad_norm": 0.2924327850341797,
    "learning_rate": 1.210728338552959e-05,
    "epoch": 1.9740892422174041,
    "step": 147500
  },
  {
    "loss": 0.1544,
    "grad_norm": 0.26443126797676086,
    "learning_rate": 1.2080516073770711e-05,
    "epoch": 1.980781070157124,
    "step": 148000
  },
  {
    "loss": 0.1414,
    "grad_norm": 0.2602475583553314,
    "learning_rate": 1.2053802296635351e-05,
    "epoch": 1.9874728980968441,
    "step": 148500
  },
  {
    "loss": 0.1314,
    "grad_norm": 0.2294432669878006,
    "learning_rate": 1.2027034984876468e-05,
    "epoch": 1.9941647260365643,
    "step": 149000
  },
  {
    "eval_loss": 0.14369156956672668,
    "eval_accuracy": 0.9714258946973955,
    "eval_runtime": 127.4876,
    "eval_samples_per_second": 586.081,
    "eval_steps_per_second": 73.262,
    "epoch": 2.0,
    "step": 149436
  },
  {
    "loss": 0.138,
    "grad_norm": 0.24218550324440002,
    "learning_rate": 1.2000267673117589e-05,
    "epoch": 2.000856553976284,
    "step": 149500
  },
  {
    "loss": 0.1364,
    "grad_norm": 0.26542672514915466,
    "learning_rate": 1.197350036135871e-05,
    "epoch": 2.007548381916004,
    "step": 150000
  },
  {
    "loss": 0.143,
    "grad_norm": 0.26799073815345764,
    "learning_rate": 1.1946786584223346e-05,
    "epoch": 2.0142402098557244,
    "step": 150500
  },
  {
    "loss": 0.1469,
    "grad_norm": 0.2389964610338211,
    "learning_rate": 1.1920019272464468e-05,
    "epoch": 2.0209320377954443,
    "step": 151000
  },
  {
    "loss": 0.1469,
    "grad_norm": 6.161658763885498,
    "learning_rate": 1.1893251960705588e-05,
    "epoch": 2.027623865735164,
    "step": 151500
  },
  {
    "loss": 0.1455,
    "grad_norm": 0.258696049451828,
    "learning_rate": 1.1866484648946708e-05,
    "epoch": 2.034315693674884,
    "step": 152000
  },
  {
    "loss": 0.1349,
    "grad_norm": 0.23370081186294556,
    "learning_rate": 1.1839770871811345e-05,
    "epoch": 2.0410075216146044,
    "step": 152500
  },
  {
    "loss": 0.1589,
    "grad_norm": 0.32006406784057617,
    "learning_rate": 1.1813003560052466e-05,
    "epoch": 2.0476993495543243,
    "step": 153000
  },
  {
    "loss": 0.1372,
    "grad_norm": 0.22533252835273743,
    "learning_rate": 1.1786236248293586e-05,
    "epoch": 2.054391177494044,
    "step": 153500
  },
  {
    "loss": 0.1414,
    "grad_norm": 3.1347477436065674,
    "learning_rate": 1.1759468936534703e-05,
    "epoch": 2.061083005433764,
    "step": 154000
  },
  {
    "loss": 0.1398,
    "grad_norm": 6.234616279602051,
    "learning_rate": 1.1732755159399343e-05,
    "epoch": 2.0677748333734844,
    "step": 154500
  },
  {
    "loss": 0.1411,
    "grad_norm": 3.2772533893585205,
    "learning_rate": 1.1705987847640464e-05,
    "epoch": 2.0744666613132043,
    "step": 155000
  },
  {
    "loss": 0.129,
    "grad_norm": 0.22416844964027405,
    "learning_rate": 1.1679220535881582e-05,
    "epoch": 2.0811584892529242,
    "step": 155500
  },
  {
    "loss": 0.1322,
    "grad_norm": 0.1968705803155899,
    "learning_rate": 1.1652453224122702e-05,
    "epoch": 2.087850317192644,
    "step": 156000
  },
  {
    "loss": 0.1435,
    "grad_norm": 0.24840226769447327,
    "learning_rate": 1.1625739446987341e-05,
    "epoch": 2.0945421451323645,
    "step": 156500
  },
  {
    "loss": 0.1599,
    "grad_norm": 0.22776339948177338,
    "learning_rate": 1.159897213522846e-05,
    "epoch": 2.1012339730720844,
    "step": 157000
  },
  {
    "loss": 0.1417,
    "grad_norm": 0.2524677515029907,
    "learning_rate": 1.157220482346958e-05,
    "epoch": 2.1079258010118043,
    "step": 157500
  },
  {
    "loss": 0.1424,
    "grad_norm": 0.23933693766593933,
    "learning_rate": 1.15454375117107e-05,
    "epoch": 2.1146176289515246,
    "step": 158000
  },
  {
    "loss": 0.1354,
    "grad_norm": 0.2154379040002823,
    "learning_rate": 1.1518723734575337e-05,
    "epoch": 2.1213094568912445,
    "step": 158500
  },
  {
    "loss": 0.143,
    "grad_norm": 3.2560226917266846,
    "learning_rate": 1.1491956422816458e-05,
    "epoch": 2.1280012848309644,
    "step": 159000
  },
  {
    "loss": 0.1248,
    "grad_norm": 0.20704138278961182,
    "learning_rate": 1.1465189111057578e-05,
    "epoch": 2.1346931127706843,
    "step": 159500
  },
  {
    "loss": 0.1422,
    "grad_norm": 0.27374911308288574,
    "learning_rate": 1.1438421799298698e-05,
    "epoch": 2.1413849407104046,
    "step": 160000
  },
  {
    "loss": 0.1284,
    "grad_norm": 0.2185058891773224,
    "learning_rate": 1.1411708022163335e-05,
    "epoch": 2.1480767686501245,
    "step": 160500
  },
  {
    "loss": 0.1503,
    "grad_norm": 0.3039049506187439,
    "learning_rate": 1.1384940710404455e-05,
    "epoch": 2.1547685965898444,
    "step": 161000
  },
  {
    "loss": 0.1709,
    "grad_norm": 0.3200032711029053,
    "learning_rate": 1.1358173398645576e-05,
    "epoch": 2.1614604245295643,
    "step": 161500
  },
  {
    "loss": 0.1412,
    "grad_norm": 3.0779736042022705,
    "learning_rate": 1.1331406086886696e-05,
    "epoch": 2.1681522524692847,
    "step": 162000
  },
  {
    "loss": 0.1566,
    "grad_norm": 3.081754684448242,
    "learning_rate": 1.1304692309751333e-05,
    "epoch": 2.1748440804090046,
    "step": 162500
  },
  {
    "loss": 0.1432,
    "grad_norm": 0.31114140152931213,
    "learning_rate": 1.1277924997992453e-05,
    "epoch": 2.1815359083487245,
    "step": 163000
  },
  {
    "loss": 0.1512,
    "grad_norm": 0.3025793135166168,
    "learning_rate": 1.1251157686233572e-05,
    "epoch": 2.1882277362884444,
    "step": 163500
  },
  {
    "loss": 0.1503,
    "grad_norm": 0.228149875998497,
    "learning_rate": 1.1224390374474692e-05,
    "epoch": 2.1949195642281647,
    "step": 164000
  },
  {
    "loss": 0.1243,
    "grad_norm": 0.23363053798675537,
    "learning_rate": 1.119767659733933e-05,
    "epoch": 2.2016113921678846,
    "step": 164500
  },
  {
    "loss": 0.1449,
    "grad_norm": 0.25118398666381836,
    "learning_rate": 1.117090928558045e-05,
    "epoch": 2.2083032201076045,
    "step": 165000
  },
  {
    "loss": 0.134,
    "grad_norm": 0.2116517871618271,
    "learning_rate": 1.114414197382157e-05,
    "epoch": 2.2149950480473244,
    "step": 165500
  },
  {
    "loss": 0.1258,
    "grad_norm": 0.2080772966146469,
    "learning_rate": 1.111737466206269e-05,
    "epoch": 2.2216868759870447,
    "step": 166000
  },
  {
    "loss": 0.1544,
    "grad_norm": 0.24341978132724762,
    "learning_rate": 1.109060735030381e-05,
    "epoch": 2.2283787039267646,
    "step": 166500
  },
  {
    "loss": 0.1322,
    "grad_norm": 3.2814300060272217,
    "learning_rate": 1.1063893573168447e-05,
    "epoch": 2.2350705318664845,
    "step": 167000
  },
  {
    "loss": 0.1358,
    "grad_norm": 0.22269316017627716,
    "learning_rate": 1.1037126261409568e-05,
    "epoch": 2.241762359806205,
    "step": 167500
  },
  {
    "loss": 0.1245,
    "grad_norm": 0.22068169713020325,
    "learning_rate": 1.1010358949650688e-05,
    "epoch": 2.2484541877459248,
    "step": 168000
  },
  {
    "loss": 0.1228,
    "grad_norm": 3.0804972648620605,
    "learning_rate": 1.0983591637891808e-05,
    "epoch": 2.2551460156856447,
    "step": 168500
  },
  {
    "loss": 0.1372,
    "grad_norm": 0.2977652847766876,
    "learning_rate": 1.0956877860756445e-05,
    "epoch": 2.2618378436253646,
    "step": 169000
  },
  {
    "loss": 0.1317,
    "grad_norm": 0.2333347052335739,
    "learning_rate": 1.0930110548997565e-05,
    "epoch": 2.268529671565085,
    "step": 169500
  },
  {
    "loss": 0.1165,
    "grad_norm": 3.1576883792877197,
    "learning_rate": 1.0903343237238686e-05,
    "epoch": 2.275221499504805,
    "step": 170000
  },
  {
    "loss": 0.1468,
    "grad_norm": 0.2561901807785034,
    "learning_rate": 1.0876575925479804e-05,
    "epoch": 2.2819133274445247,
    "step": 170500
  },
  {
    "loss": 0.1546,
    "grad_norm": 0.3265466094017029,
    "learning_rate": 1.0849862148344443e-05,
    "epoch": 2.2886051553842446,
    "step": 171000
  },
  {
    "loss": 0.1464,
    "grad_norm": 0.24628953635692596,
    "learning_rate": 1.0823094836585563e-05,
    "epoch": 2.295296983323965,
    "step": 171500
  },
  {
    "loss": 0.1241,
    "grad_norm": 0.20601969957351685,
    "learning_rate": 1.0796327524826682e-05,
    "epoch": 2.301988811263685,
    "step": 172000
  },
  {
    "loss": 0.1615,
    "grad_norm": 0.254069983959198,
    "learning_rate": 1.0769560213067802e-05,
    "epoch": 2.3086806392034047,
    "step": 172500
  },
  {
    "loss": 0.1606,
    "grad_norm": 0.2807835638523102,
    "learning_rate": 1.0742846435932439e-05,
    "epoch": 2.315372467143125,
    "step": 173000
  },
  {
    "loss": 0.1327,
    "grad_norm": 0.2112344354391098,
    "learning_rate": 1.071607912417356e-05,
    "epoch": 2.322064295082845,
    "step": 173500
  },
  {
    "loss": 0.1421,
    "grad_norm": 0.22745315730571747,
    "learning_rate": 1.068931181241468e-05,
    "epoch": 2.328756123022565,
    "step": 174000
  },
  {
    "loss": 0.1458,
    "grad_norm": 0.2836983799934387,
    "learning_rate": 1.06625445006558e-05,
    "epoch": 2.3354479509622847,
    "step": 174500
  },
  {
    "loss": 0.13,
    "grad_norm": 0.24284812808036804,
    "learning_rate": 1.0635830723520437e-05,
    "epoch": 2.3421397789020046,
    "step": 175000
  },
  {
    "loss": 0.1555,
    "grad_norm": 0.233572855591774,
    "learning_rate": 1.0609063411761557e-05,
    "epoch": 2.348831606841725,
    "step": 175500
  },
  {
    "loss": 0.1378,
    "grad_norm": 0.227285698056221,
    "learning_rate": 1.0582296100002678e-05,
    "epoch": 2.355523434781445,
    "step": 176000
  },
  {
    "loss": 0.1434,
    "grad_norm": 3.188983678817749,
    "learning_rate": 1.0555528788243798e-05,
    "epoch": 2.3622152627211648,
    "step": 176500
  },
  {
    "loss": 0.1575,
    "grad_norm": 0.25989776849746704,
    "learning_rate": 1.0528868545731953e-05,
    "epoch": 2.368907090660885,
    "step": 177000
  },
  {
    "loss": 0.1516,
    "grad_norm": 0.2619112730026245,
    "learning_rate": 1.0502101233973072e-05,
    "epoch": 2.375598918600605,
    "step": 177500
  },
  {
    "loss": 0.1456,
    "grad_norm": 0.2572765052318573,
    "learning_rate": 1.0475333922214192e-05,
    "epoch": 2.382290746540325,
    "step": 178000
  },
  {
    "loss": 0.141,
    "grad_norm": 0.26385968923568726,
    "learning_rate": 1.0448566610455312e-05,
    "epoch": 2.388982574480045,
    "step": 178500
  },
  {
    "loss": 0.1444,
    "grad_norm": 0.2147870808839798,
    "learning_rate": 1.0421799298696433e-05,
    "epoch": 2.395674402419765,
    "step": 179000
  },
  {
    "loss": 0.1353,
    "grad_norm": 0.20083285868167877,
    "learning_rate": 1.0395031986937553e-05,
    "epoch": 2.402366230359485,
    "step": 179500
  },
  {
    "loss": 0.1324,
    "grad_norm": 0.19337156414985657,
    "learning_rate": 1.0368264675178672e-05,
    "epoch": 2.409058058299205,
    "step": 180000
  },
  {
    "loss": 0.1411,
    "grad_norm": 0.2783479392528534,
    "learning_rate": 1.0341497363419792e-05,
    "epoch": 2.415749886238925,
    "step": 180500
  },
  {
    "loss": 0.1604,
    "grad_norm": 0.2841944694519043,
    "learning_rate": 1.0314783586284429e-05,
    "epoch": 2.422441714178645,
    "step": 181000
  },
  {
    "loss": 0.1396,
    "grad_norm": 0.21926428377628326,
    "learning_rate": 1.028801627452555e-05,
    "epoch": 2.429133542118365,
    "step": 181500
  },
  {
    "loss": 0.1708,
    "grad_norm": 0.34813180565834045,
    "learning_rate": 1.026130249739019e-05,
    "epoch": 2.435825370058085,
    "step": 182000
  },
  {
    "loss": 0.1466,
    "grad_norm": 0.2743101418018341,
    "learning_rate": 1.0234535185631306e-05,
    "epoch": 2.4425171979978053,
    "step": 182500
  },
  {
    "loss": 0.1391,
    "grad_norm": 0.23073548078536987,
    "learning_rate": 1.0207767873872427e-05,
    "epoch": 2.449209025937525,
    "step": 183000
  },
  {
    "loss": 0.1446,
    "grad_norm": 2.970438003540039,
    "learning_rate": 1.0181000562113547e-05,
    "epoch": 2.455900853877245,
    "step": 183500
  },
  {
    "loss": 0.1496,
    "grad_norm": 3.0761406421661377,
    "learning_rate": 1.0154233250354667e-05,
    "epoch": 2.462592681816965,
    "step": 184000
  },
  {
    "loss": 0.1565,
    "grad_norm": 0.2847681939601898,
    "learning_rate": 1.012746593859579e-05,
    "epoch": 2.469284509756685,
    "step": 184500
  },
  {
    "loss": 0.1568,
    "grad_norm": 0.25146231055259705,
    "learning_rate": 1.0100698626836906e-05,
    "epoch": 2.4759763376964052,
    "step": 185000
  },
  {
    "loss": 0.1374,
    "grad_norm": 0.23732709884643555,
    "learning_rate": 1.0073931315078027e-05,
    "epoch": 2.482668165636125,
    "step": 185500
  },
  {
    "loss": 0.126,
    "grad_norm": 0.17759890854358673,
    "learning_rate": 1.0047217537942667e-05,
    "epoch": 2.489359993575845,
    "step": 186000
  },
  {
    "loss": 0.1469,
    "grad_norm": 2.976754665374756,
    "learning_rate": 1.0020450226183784e-05,
    "epoch": 2.4960518215155654,
    "step": 186500
  },
  {
    "loss": 0.1338,
    "grad_norm": 0.23710593581199646,
    "learning_rate": 9.993682914424904e-06,
    "epoch": 2.5027436494552853,
    "step": 187000
  },
  {
    "loss": 0.135,
    "grad_norm": 3.059995174407959,
    "learning_rate": 9.966915602666024e-06,
    "epoch": 2.509435477395005,
    "step": 187500
  },
  {
    "loss": 0.1576,
    "grad_norm": 0.27123233675956726,
    "learning_rate": 9.940148290907145e-06,
    "epoch": 2.5161273053347255,
    "step": 188000
  },
  {
    "loss": 0.1452,
    "grad_norm": 0.26277223229408264,
    "learning_rate": 9.913434513771782e-06,
    "epoch": 2.5228191332744454,
    "step": 188500
  },
  {
    "loss": 0.1381,
    "grad_norm": 0.23762081563472748,
    "learning_rate": 9.886667202012904e-06,
    "epoch": 2.5295109612141653,
    "step": 189000
  },
  {
    "loss": 0.1272,
    "grad_norm": 0.21080049872398376,
    "learning_rate": 9.859899890254022e-06,
    "epoch": 2.536202789153885,
    "step": 189500
  },
  {
    "loss": 0.1333,
    "grad_norm": 0.19217242300510406,
    "learning_rate": 9.833132578495143e-06,
    "epoch": 2.542894617093605,
    "step": 190000
  },
  {
    "loss": 0.1475,
    "grad_norm": 2.848052501678467,
    "learning_rate": 9.806418801359781e-06,
    "epoch": 2.5495864450333254,
    "step": 190500
  },
  {
    "loss": 0.1387,
    "grad_norm": 0.23039250075817108,
    "learning_rate": 9.7796514896009e-06,
    "epoch": 2.5562782729730453,
    "step": 191000
  },
  {
    "loss": 0.1727,
    "grad_norm": 5.79924201965332,
    "learning_rate": 9.752937712465538e-06,
    "epoch": 2.5629701009127652,
    "step": 191500
  },
  {
    "loss": 0.1348,
    "grad_norm": 0.27604565024375916,
    "learning_rate": 9.726170400706659e-06,
    "epoch": 2.5696619288524856,
    "step": 192000
  },
  {
    "loss": 0.1462,
    "grad_norm": 0.24050408601760864,
    "learning_rate": 9.699403088947777e-06,
    "epoch": 2.5763537567922055,
    "step": 192500
  },
  {
    "loss": 0.1433,
    "grad_norm": 3.247394323348999,
    "learning_rate": 9.672635777188898e-06,
    "epoch": 2.5830455847319254,
    "step": 193000
  },
  {
    "loss": 0.1479,
    "grad_norm": 0.2400364726781845,
    "learning_rate": 9.645868465430018e-06,
    "epoch": 2.5897374126716453,
    "step": 193500
  },
  {
    "loss": 0.1343,
    "grad_norm": 2.9666881561279297,
    "learning_rate": 9.619101153671138e-06,
    "epoch": 2.596429240611365,
    "step": 194000
  },
  {
    "loss": 0.1322,
    "grad_norm": 0.23182645440101624,
    "learning_rate": 9.592333841912259e-06,
    "epoch": 2.6031210685510855,
    "step": 194500
  },
  {
    "loss": 0.1368,
    "grad_norm": 0.2319377064704895,
    "learning_rate": 9.565566530153377e-06,
    "epoch": 2.6098128964908054,
    "step": 195000
  },
  {
    "loss": 0.1543,
    "grad_norm": 0.23588363826274872,
    "learning_rate": 9.538852753018016e-06,
    "epoch": 2.6165047244305253,
    "step": 195500
  },
  {
    "loss": 0.1463,
    "grad_norm": 0.22439232468605042,
    "learning_rate": 9.512085441259134e-06,
    "epoch": 2.6231965523702456,
    "step": 196000
  },
  {
    "loss": 0.1404,
    "grad_norm": 0.24332691729068756,
    "learning_rate": 9.485318129500255e-06,
    "epoch": 2.6298883803099655,
    "step": 196500
  },
  {
    "loss": 0.1566,
    "grad_norm": 5.964789867401123,
    "learning_rate": 9.458550817741375e-06,
    "epoch": 2.6365802082496854,
    "step": 197000
  },
  {
    "loss": 0.1418,
    "grad_norm": 0.23948974907398224,
    "learning_rate": 9.431837040606012e-06,
    "epoch": 2.6432720361894058,
    "step": 197500
  },
  {
    "loss": 0.1216,
    "grad_norm": 0.23034879565238953,
    "learning_rate": 9.405069728847132e-06,
    "epoch": 2.6499638641291257,
    "step": 198000
  },
  {
    "loss": 0.1489,
    "grad_norm": 2.9011785984039307,
    "learning_rate": 9.378302417088253e-06,
    "epoch": 2.6566556920688456,
    "step": 198500
  },
  {
    "loss": 0.1465,
    "grad_norm": 0.23169589042663574,
    "learning_rate": 9.351535105329373e-06,
    "epoch": 2.6633475200085654,
    "step": 199000
  },
  {
    "loss": 0.1399,
    "grad_norm": 0.2572190463542938,
    "learning_rate": 9.32482132819401e-06,
    "epoch": 2.6700393479482853,
    "step": 199500
  },
  {
    "loss": 0.1404,
    "grad_norm": 0.2612747550010681,
    "learning_rate": 9.29805401643513e-06,
    "epoch": 2.6767311758880057,
    "step": 200000
  },
  {
    "loss": 0.1357,
    "grad_norm": 0.23516389727592468,
    "learning_rate": 9.27128670467625e-06,
    "epoch": 2.6834230038277256,
    "step": 200500
  },
  {
    "loss": 0.1537,
    "grad_norm": 3.166128635406494,
    "learning_rate": 9.24451939291737e-06,
    "epoch": 2.6901148317674455,
    "step": 201000
  },
  {
    "loss": 0.1413,
    "grad_norm": 0.2532770037651062,
    "learning_rate": 9.217805615782008e-06,
    "epoch": 2.696806659707166,
    "step": 201500
  },
  {
    "loss": 0.1338,
    "grad_norm": 2.871020793914795,
    "learning_rate": 9.191038304023128e-06,
    "epoch": 2.7034984876468857,
    "step": 202000
  },
  {
    "loss": 0.1357,
    "grad_norm": 0.23843719065189362,
    "learning_rate": 9.164270992264248e-06,
    "epoch": 2.7101903155866056,
    "step": 202500
  },
  {
    "loss": 0.1374,
    "grad_norm": 0.22329993546009064,
    "learning_rate": 9.137503680505367e-06,
    "epoch": 2.7168821435263255,
    "step": 203000
  },
  {
    "loss": 0.1453,
    "grad_norm": 0.24189412593841553,
    "learning_rate": 9.110789903370006e-06,
    "epoch": 2.7235739714660454,
    "step": 203500
  },
  {
    "loss": 0.1568,
    "grad_norm": 2.7778258323669434,
    "learning_rate": 9.084022591611126e-06,
    "epoch": 2.7302657994057657,
    "step": 204000
  },
  {
    "loss": 0.1329,
    "grad_norm": 0.23830290138721466,
    "learning_rate": 9.057255279852244e-06,
    "epoch": 2.7369576273454856,
    "step": 204500
  },
  {
    "loss": 0.1541,
    "grad_norm": 2.746748924255371,
    "learning_rate": 9.030487968093365e-06,
    "epoch": 2.7436494552852055,
    "step": 205000
  },
  {
    "loss": 0.1284,
    "grad_norm": 0.2257262021303177,
    "learning_rate": 9.003720656334485e-06,
    "epoch": 2.750341283224926,
    "step": 205500
  },
  {
    "loss": 0.1431,
    "grad_norm": 0.2242281436920166,
    "learning_rate": 8.977006879199122e-06,
    "epoch": 2.7570331111646458,
    "step": 206000
  },
  {
    "loss": 0.1344,
    "grad_norm": 0.23285318911075592,
    "learning_rate": 8.950239567440242e-06,
    "epoch": 2.7637249391043657,
    "step": 206500
  },
  {
    "loss": 0.133,
    "grad_norm": 0.2427293211221695,
    "learning_rate": 8.92352579030488e-06,
    "epoch": 2.770416767044086,
    "step": 207000
  },
  {
    "loss": 0.1351,
    "grad_norm": 2.78999400138855,
    "learning_rate": 8.896758478546e-06,
    "epoch": 2.777108594983806,
    "step": 207500
  },
  {
    "loss": 0.1155,
    "grad_norm": 0.21188415586948395,
    "learning_rate": 8.869991166787122e-06,
    "epoch": 2.783800422923526,
    "step": 208000
  },
  {
    "loss": 0.1563,
    "grad_norm": 0.2570946514606476,
    "learning_rate": 8.84322385502824e-06,
    "epoch": 2.7904922508632457,
    "step": 208500
  },
  {
    "loss": 0.1273,
    "grad_norm": 0.21825110912322998,
    "learning_rate": 8.81645654326936e-06,
    "epoch": 2.7971840788029656,
    "step": 209000
  },
  {
    "loss": 0.1302,
    "grad_norm": 0.21165989339351654,
    "learning_rate": 8.789689231510479e-06,
    "epoch": 2.803875906742686,
    "step": 209500
  },
  {
    "loss": 0.1393,
    "grad_norm": 0.22319026291370392,
    "learning_rate": 8.7629219197516e-06,
    "epoch": 2.810567734682406,
    "step": 210000
  },
  {
    "loss": 0.1496,
    "grad_norm": 0.2934829592704773,
    "learning_rate": 8.73615460799272e-06,
    "epoch": 2.8172595626221257,
    "step": 210500
  },
  {
    "loss": 0.1308,
    "grad_norm": 0.2460164576768875,
    "learning_rate": 8.709440830857357e-06,
    "epoch": 2.823951390561846,
    "step": 211000
  },
  {
    "loss": 0.1627,
    "grad_norm": 0.2974553108215332,
    "learning_rate": 8.682673519098479e-06,
    "epoch": 2.830643218501566,
    "step": 211500
  },
  {
    "loss": 0.134,
    "grad_norm": 0.26627105474472046,
    "learning_rate": 8.655906207339597e-06,
    "epoch": 2.837335046441286,
    "step": 212000
  },
  {
    "loss": 0.153,
    "grad_norm": 0.29753562808036804,
    "learning_rate": 8.629138895580718e-06,
    "epoch": 2.8440268743810058,
    "step": 212500
  },
  {
    "loss": 0.1595,
    "grad_norm": 0.30782103538513184,
    "learning_rate": 8.602425118445356e-06,
    "epoch": 2.8507187023207257,
    "step": 213000
  },
  {
    "loss": 0.1418,
    "grad_norm": 0.24247682094573975,
    "learning_rate": 8.575657806686475e-06,
    "epoch": 2.857410530260446,
    "step": 213500
  },
  {
    "loss": 0.1428,
    "grad_norm": 0.22197726368904114,
    "learning_rate": 8.548890494927595e-06,
    "epoch": 2.864102358200166,
    "step": 214000
  },
  {
    "loss": 0.136,
    "grad_norm": 0.2598801255226135,
    "learning_rate": 8.522123183168714e-06,
    "epoch": 2.870794186139886,
    "step": 214500
  },
  {
    "loss": 0.1451,
    "grad_norm": 0.2583724856376648,
    "learning_rate": 8.495409406033352e-06,
    "epoch": 2.877486014079606,
    "step": 215000
  },
  {
    "loss": 0.1505,
    "grad_norm": 0.26354530453681946,
    "learning_rate": 8.468642094274473e-06,
    "epoch": 2.884177842019326,
    "step": 215500
  },
  {
    "loss": 0.1406,
    "grad_norm": 0.2472049444913864,
    "learning_rate": 8.441874782515593e-06,
    "epoch": 2.890869669959046,
    "step": 216000
  },
  {
    "loss": 0.1483,
    "grad_norm": 0.26525744795799255,
    "learning_rate": 8.415107470756713e-06,
    "epoch": 2.8975614978987663,
    "step": 216500
  },
  {
    "loss": 0.1417,
    "grad_norm": 0.23407579958438873,
    "learning_rate": 8.38839369362135e-06,
    "epoch": 2.904253325838486,
    "step": 217000
  },
  {
    "loss": 0.1512,
    "grad_norm": 2.827772617340088,
    "learning_rate": 8.36162638186247e-06,
    "epoch": 2.910945153778206,
    "step": 217500
  },
  {
    "loss": 0.1382,
    "grad_norm": 0.24094358086585999,
    "learning_rate": 8.334859070103591e-06,
    "epoch": 2.917636981717926,
    "step": 218000
  },
  {
    "loss": 0.1512,
    "grad_norm": 0.2688380181789398,
    "learning_rate": 8.30809175834471e-06,
    "epoch": 2.924328809657646,
    "step": 218500
  },
  {
    "loss": 0.1304,
    "grad_norm": 0.23531177639961243,
    "learning_rate": 8.28132444658583e-06,
    "epoch": 2.931020637597366,
    "step": 219000
  },
  {
    "loss": 0.1484,
    "grad_norm": 0.23667532205581665,
    "learning_rate": 8.254610669450468e-06,
    "epoch": 2.937712465537086,
    "step": 219500
  },
  {
    "loss": 0.1304,
    "grad_norm": 0.22399115562438965,
    "learning_rate": 8.227843357691587e-06,
    "epoch": 2.944404293476806,
    "step": 220000
  },
  {
    "loss": 0.1434,
    "grad_norm": 0.25467392802238464,
    "learning_rate": 8.201076045932707e-06,
    "epoch": 2.9510961214165263,
    "step": 220500
  },
  {
    "loss": 0.111,
    "grad_norm": 0.1973181813955307,
    "learning_rate": 8.174308734173828e-06,
    "epoch": 2.9577879493562462,
    "step": 221000
  },
  {
    "loss": 0.1332,
    "grad_norm": 0.23017388582229614,
    "learning_rate": 8.147594957038465e-06,
    "epoch": 2.964479777295966,
    "step": 221500
  },
  {
    "loss": 0.1341,
    "grad_norm": 0.24921083450317383,
    "learning_rate": 8.120827645279585e-06,
    "epoch": 2.971171605235686,
    "step": 222000
  },
  {
    "loss": 0.1426,
    "grad_norm": 2.837090492248535,
    "learning_rate": 8.094060333520705e-06,
    "epoch": 2.9778634331754064,
    "step": 222500
  },
  {
    "loss": 0.1366,
    "grad_norm": 0.22787106037139893,
    "learning_rate": 8.067293021761825e-06,
    "epoch": 2.9845552611151263,
    "step": 223000
  },
  {
    "loss": 0.1437,
    "grad_norm": 0.2285860925912857,
    "learning_rate": 8.040579244626462e-06,
    "epoch": 2.991247089054846,
    "step": 223500
  },
  {
    "loss": 0.1463,
    "grad_norm": 0.22492344677448273,
    "learning_rate": 8.013811932867583e-06,
    "epoch": 2.997938916994566,
    "step": 224000
  },
  {
    "eval_loss": 0.14033646881580353,
    "eval_accuracy": 0.9714258946973955,
    "eval_runtime": 130.9123,
    "eval_samples_per_second": 570.749,
    "eval_steps_per_second": 71.345,
    "epoch": 3.0,
    "step": 224154
  },
  {
    "train_runtime": 10343.8483,
    "train_samples_per_second": 288.937,
    "train_steps_per_second": 36.117,
    "total_flos": 2.358659672441256e+17,
    "train_loss": 0.14260237144005208,
    "epoch": 3.0,
    "step": 224154
  }
]